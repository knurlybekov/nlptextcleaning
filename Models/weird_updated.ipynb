{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-04T16:46:01.733853Z",
     "start_time": "2025-03-04T16:46:01.116487Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('use_this_data/rest_data_last.csv')\n",
    "# df = pd.read_csv('data_2.csv')\n",
    "df = pd.read_csv('use_this_data/data_features.csv')\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  category                                               text  \\\n",
       "0     arts  rob delaney vir das galen hopper samson kayo g...   \n",
       "1     arts  andris nelsons conducts a joint concert of the...   \n",
       "2     arts  warner music group has brought on sherry tan t...   \n",
       "3     arts  adele will explore what she s been going throu...   \n",
       "4     arts  you are using an older browser version. please...   \n",
       "\n",
       "                                          clean_text  matches  \\\n",
       "0  rob hopper samson kayo guz khan nick ross lee ...     True   \n",
       "1  nelson conduct joint concert boston symphony o...     True   \n",
       "2  warner music group brought sherry tan head mus...     True   \n",
       "3  explore going album set explore going album ol...     True   \n",
       "4  older browser version please use version best ...     True   \n",
       "\n",
       "                                            features  \n",
       "0  rob hopper samson kayo guz nick ross lee harry...  \n",
       "1  nelson conduct joint concert boston symphony o...  \n",
       "2  warner music group brought sherry tan head mus...  \n",
       "3  explore going album set explore going album ol...  \n",
       "4  browser version please use version experience ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>matches</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arts</td>\n",
       "      <td>rob delaney vir das galen hopper samson kayo g...</td>\n",
       "      <td>rob hopper samson kayo guz khan nick ross lee ...</td>\n",
       "      <td>True</td>\n",
       "      <td>rob hopper samson kayo guz nick ross lee harry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arts</td>\n",
       "      <td>andris nelsons conducts a joint concert of the...</td>\n",
       "      <td>nelson conduct joint concert boston symphony o...</td>\n",
       "      <td>True</td>\n",
       "      <td>nelson conduct joint concert boston symphony o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arts</td>\n",
       "      <td>warner music group has brought on sherry tan t...</td>\n",
       "      <td>warner music group brought sherry tan head mus...</td>\n",
       "      <td>True</td>\n",
       "      <td>warner music group brought sherry tan head mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arts</td>\n",
       "      <td>adele will explore what she s been going throu...</td>\n",
       "      <td>explore going album set explore going album ol...</td>\n",
       "      <td>True</td>\n",
       "      <td>explore going album set explore going album ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arts</td>\n",
       "      <td>you are using an older browser version. please...</td>\n",
       "      <td>older browser version please use version best ...</td>\n",
       "      <td>True</td>\n",
       "      <td>browser version please use version experience ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T16:46:26.159267Z",
     "start_time": "2025-03-04T16:46:22.724794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import sent_tokenize\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "weighted_dict= {}\n",
    "\n",
    "new_keywords = {\n",
    "    'arts': [\n",
    "        'music','show','series','park','best','million','event','back','work','state',\n",
    "        'way','may','get','group','take','world','community','season','good','school'\n",
    "    ],\n",
    "    'crime': [\n",
    "        'police','court','law','state','case','county','old','found','may','hearing',\n",
    "        'death','federal','prison','told','justice','man','right','officer','according','president'\n",
    "    ],\n",
    "    'disaster': [\n",
    "        'fire','water','police','air','state','rescue','city','may','area','county',\n",
    "        'home','near','according','news','around','could','back','national','help','road'\n",
    "    ],\n",
    "    'economy': [\n",
    "        'company','may','per','market','million','price','tax','billion','business','government',\n",
    "        'state','since','industry','group','percent','use','get','made','work','according'\n",
    "    ],\n",
    "    'education': [\n",
    "        'school','university','education','high','learning','college','state','student','class',\n",
    "        'community','work','program','support','help','board','government','president','covid','public','national'\n",
    "    ],\n",
    "    'environmental': [\n",
    "        'energy','park','waste','water','power','market','state','company','north','management',\n",
    "        'solar','group','renewable','county','world','wildlife','city','wind','river','industry'\n",
    "    ],\n",
    "    'health': [\n",
    "        'health','covid','care','market','medical','pandemic','hospital','state','may','vaccine',\n",
    "        'public','food','disease','get','help','company','global','well','virus','work'\n",
    "    ],\n",
    "    'humaninterest': [\n",
    "        'award','size','get','act','home','back','winning','best','statement','texas',\n",
    "        'team','may','good','world','well','ownership','beneficial','plant','second','top'\n",
    "    ],\n",
    "    'labour': [\n",
    "        'work','health','security','working','pandemic','retirement','may','covid','could','get',\n",
    "        'state','make','job','business','home','help','social','market','city','week'\n",
    "    ],\n",
    "    'lifestyle': [\n",
    "        'home','travel','get','beauty','bridge','make','summer','may','way','life',\n",
    "        'work','back','million','come','food','covid','want','pandemic','best','business'\n",
    "    ],\n",
    "    # 'other': [\n",
    "    #     'state','market','game','covid','government','may','could','rub','wednesday','home',\n",
    "    #     'high','city','get','school','pandemic','health','make','season','back','team'\n",
    "    # ],\n",
    "    'other': [\n",
    "        'may','could','rub','wednesday','home',\n",
    "        'high','city','get','school','health','make','season','back','team'\n",
    "    ],\n",
    "    'politics': [\n",
    "        'government','state','president','minister','data','security','public','city','international','support',\n",
    "        'tuesday','news','united','may','covid','national','pandemic','help','house','health'\n",
    "    ],\n",
    "    'religion': [\n",
    "        'church','life','school','family','may','community','world','way','come','work',\n",
    "        'home','covid','old','get','back','spiritual','god','state','well','city'\n",
    "    ],\n",
    "    'science': [\n",
    "        'market','research','space','report','global','data','work','company','study','industry',\n",
    "        'may','science','medical','could','high','design','engineering','covid','well','use'\n",
    "    ],\n",
    "    'social': [\n",
    "        'health','care','social','work','government','covid','may','baby','state','abortion',\n",
    "        'support','home','get','life','pandemic','according','community','make','city','help'\n",
    "    ],\n",
    "    'sport': [\n",
    "        'team','game','season','back','world','get','match','second','sport','four',\n",
    "        'league','win','best','final','play','tournament','coach','right','open','championship'\n",
    "    ],\n",
    "    'unrest': [\n",
    "        'israel','police','war','government','city','violence','shooting','israeli','military','may',\n",
    "        'wednesday','state','gun','country','president','old','come','security','world','home'\n",
    "    ],\n",
    "    'weather': [\n",
    "        'climate','change','heat','weather','water','high','carbon','could','global','national',\n",
    "        'state','may','risk','area','service','according','world','friday','rain','report'\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# 3) Create a copy so we don't modify original directly\n",
    "updated_dict = copy.deepcopy(weighted_dict)\n",
    "\n",
    "# 4) Define a default weight for new words\n",
    "DEFAULT_WEIGHT = 0.6\n",
    "\n",
    "# 5) Merge logic\n",
    "for category, words in new_keywords.items():\n",
    "    # If this category doesn't exist in the dictionary, create it\n",
    "    if category not in updated_dict:\n",
    "        updated_dict[category] = {}\n",
    "    \n",
    "    for w in words:\n",
    "        # Add the word only if it isn't already in the dictionary\n",
    "        if w not in updated_dict[category]:\n",
    "            updated_dict[category][w] = DEFAULT_WEIGHT\n",
    "\n",
    "# 'updated_dict' is now the merged result.\n",
    "\n",
    "\n",
    "x = df[\"clean_text\"]\n",
    "y = df[\"category\"]\n",
    "# Train the Random Forest classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test_vectorized)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "def dictionary_score(sentence, weighted_dict):\n",
    "    \"\"\"\n",
    "    Computes a score for each class based on the presence of weighted keywords.\n",
    "    \"\"\"\n",
    "    words = sentence.lower().split()\n",
    "    scores = {cls: 0 for cls in weighted_dict}\n",
    "    for cls in weighted_dict:\n",
    "        for word in words:\n",
    "            scores[cls] += weighted_dict[cls].get(word, 0)\n",
    "    return scores\n",
    "\n",
    "def classifier_predict(sentence):\n",
    "    X_sentence = vectorizer.transform([sentence])\n",
    "    probas = rf.predict_proba(X_sentence)[0]\n",
    "    return dict(zip(rf.classes_, probas))\n",
    "\n",
    "def combine_predictions(clf_pred, dict_scores, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Combine classifier probabilities and dictionary scores.\n",
    "    The parameter alpha weights the classifier output.\n",
    "    \"\"\"\n",
    "    combined = {}\n",
    "    for cls in clf_pred:\n",
    "        combined[cls] = alpha * clf_pred[cls] + (1 - alpha) * dict_scores.get(cls, 0)\n",
    "    return combined\n",
    "\n",
    "def classify_text(text, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Tokenize the text into sentences, combine classifier and dictionary scores,\n",
    "    and return the final predicted class based on majority vote.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentence_labels = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        clf_pred = classifier_predict(sentence)\n",
    "        dict_scores = dictionary_score(sentence, weighted_dict)\n",
    "        combined_scores = combine_predictions(clf_pred, dict_scores, alpha)\n",
    "        # Select the class with the highest combined score for the sentence\n",
    "        sentence_label = max(combined_scores, key=combined_scores.get)\n",
    "        sentence_labels.append(sentence_label)\n",
    "\n",
    "    # Final classification by taking the most common class (majority vote)\n",
    "    final_label = Counter(sentence_labels).most_common(1)[0][0]\n",
    "    return final_label\n",
    "\n",
    "# Example usage:\n",
    "text_row = (\"The gallery showcased a variety of paintings and sculptures. \"\n",
    "            \"A recent experiment in the laboratory produced groundbreaking results.\")\n",
    "final_prediction = classify_text(text_row, alpha=0.65)\n",
    "print(\"Final predicted class:\", final_prediction)"
   ],
   "id": "10bbbed046a3cd59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5771643663739021\n",
      "Final predicted class: economy\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T16:47:13.248198Z",
     "start_time": "2025-03-04T16:47:02.823505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dictionary_score(sentence, weighted_dict):\n",
    "    \"\"\"\n",
    "    Computes a score for each class based on the presence of weighted keywords.\n",
    "    \"\"\"\n",
    "    words = sentence.lower().split()\n",
    "    scores = {cls: 0 for cls in weighted_dict}\n",
    "    for cls in weighted_dict:\n",
    "        for word in words:\n",
    "            scores[cls] += weighted_dict[cls].get(word, 0)\n",
    "    return scores\n",
    "\n",
    "def classifier_predict(sentence):\n",
    "    \"\"\"\n",
    "    Uses the trained Random Forest and TF-IDF vectorizer to get class probabilities.\n",
    "    \"\"\"\n",
    "    X_sentence = vectorizer.transform([sentence])\n",
    "    probas = rf.predict_proba(X_sentence)[0]\n",
    "    return dict(zip(rf.classes_, probas))\n",
    "\n",
    "def combine_predictions(clf_pred, dict_scores, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Combine classifier probabilities and dictionary scores.\n",
    "    The parameter alpha weights the classifier output.\n",
    "    \"\"\"\n",
    "    combined = {}\n",
    "    for cls in clf_pred:\n",
    "        combined[cls] = alpha * clf_pred[cls] + (1 - alpha) * dict_scores.get(cls, 0)\n",
    "    return combined\n",
    "\n",
    "def classify_text(text, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Tokenize the text into sentences, combine classifier and dictionary scores,\n",
    "    and return the final predicted class based on majority vote.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentence_labels = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        clf_pred = classifier_predict(sentence)\n",
    "        dict_scores = dictionary_score(sentence, weighted_dict)\n",
    "        combined_scores = combine_predictions(clf_pred, dict_scores, alpha)\n",
    "        \n",
    "        # Select the class with the highest combined score for the sentence\n",
    "        sentence_label = max(combined_scores, key=combined_scores.get)\n",
    "        sentence_labels.append(sentence_label)\n",
    "    \n",
    "    # Final classification by taking the most common class (majority vote)\n",
    "    final_label = Counter(sentence_labels).most_common(1)[0][0]\n",
    "    return final_label\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()  # Enable progress_apply on pandas objects\n",
    "import numpy as np\n",
    "\n",
    "df[\"predicted_category\"] = df[\"clean_text\"].progress_apply(lambda x: classify_text(x, alpha=0.65))\n",
    "\n",
    "df.head()\n"
   ],
   "id": "66e3b07e69a25af6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3985/3985 [00:10<00:00, 383.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  category                                               text  \\\n",
       "0     arts  rob delaney vir das galen hopper samson kayo g...   \n",
       "1     arts  andris nelsons conducts a joint concert of the...   \n",
       "2     arts  warner music group has brought on sherry tan t...   \n",
       "3     arts  adele will explore what she s been going throu...   \n",
       "4     arts  you are using an older browser version. please...   \n",
       "\n",
       "                                          clean_text  matches  \\\n",
       "0  rob hopper samson kayo guz khan nick ross lee ...     True   \n",
       "1  nelson conduct joint concert boston symphony o...     True   \n",
       "2  warner music group brought sherry tan head mus...     True   \n",
       "3  explore going album set explore going album ol...     True   \n",
       "4  older browser version please use version best ...     True   \n",
       "\n",
       "                                            features predicted_category  \n",
       "0  rob hopper samson kayo guz nick ross lee harry...               arts  \n",
       "1  nelson conduct joint concert boston symphony o...               arts  \n",
       "2  warner music group brought sherry tan head mus...               arts  \n",
       "3  explore going album set explore going album ol...               arts  \n",
       "4  browser version please use version experience ...               arts  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>matches</th>\n",
       "      <th>features</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arts</td>\n",
       "      <td>rob delaney vir das galen hopper samson kayo g...</td>\n",
       "      <td>rob hopper samson kayo guz khan nick ross lee ...</td>\n",
       "      <td>True</td>\n",
       "      <td>rob hopper samson kayo guz nick ross lee harry...</td>\n",
       "      <td>arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arts</td>\n",
       "      <td>andris nelsons conducts a joint concert of the...</td>\n",
       "      <td>nelson conduct joint concert boston symphony o...</td>\n",
       "      <td>True</td>\n",
       "      <td>nelson conduct joint concert boston symphony o...</td>\n",
       "      <td>arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arts</td>\n",
       "      <td>warner music group has brought on sherry tan t...</td>\n",
       "      <td>warner music group brought sherry tan head mus...</td>\n",
       "      <td>True</td>\n",
       "      <td>warner music group brought sherry tan head mus...</td>\n",
       "      <td>arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arts</td>\n",
       "      <td>adele will explore what she s been going throu...</td>\n",
       "      <td>explore going album set explore going album ol...</td>\n",
       "      <td>True</td>\n",
       "      <td>explore going album set explore going album ol...</td>\n",
       "      <td>arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arts</td>\n",
       "      <td>you are using an older browser version. please...</td>\n",
       "      <td>older browser version please use version best ...</td>\n",
       "      <td>True</td>\n",
       "      <td>browser version please use version experience ...</td>\n",
       "      <td>arts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T16:47:32.209941Z",
     "start_time": "2025-03-04T16:47:32.205796Z"
    }
   },
   "cell_type": "code",
   "source": "df['predicted_category'].value_counts()",
   "id": "acd7dbb80240f103",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_category\n",
       "weather          286\n",
       "education        285\n",
       "sport            272\n",
       "religion         260\n",
       "labour           257\n",
       "health           244\n",
       "politics         243\n",
       "science          235\n",
       "disaster         228\n",
       "environmental    221\n",
       "crime            205\n",
       "lifestyle        199\n",
       "unrest           199\n",
       "arts             197\n",
       "economy          180\n",
       "humanInterest    177\n",
       "social           169\n",
       "other            128\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T16:48:54.206956Z",
     "start_time": "2025-03-04T16:47:42.776793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Example DataFrame: df with columns \"text2\" and \"total_category\"\n",
    "x = df[\"clean_text\"]\n",
    "y = df[\"predicted_category\"]\n",
    "\n",
    "# 1. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    token_pattern=r'(?u)\\b\\w\\w+\\b',\n",
    "    lowercase=True,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    # max_features=50000,\n",
    "    sublinear_tf=True,\n",
    "    norm='l2',\n",
    "    smooth_idf=True\n",
    ")\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# 3. Define parameter distributions for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"max_depth\": [5, 10, 15, 20, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"class_weight\": [\"balanced\", None, \"balanced_subsample\"],\n",
    "}\n",
    "\n",
    "# 4. Base RandomForest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 5. RandomizedSearchCV setup\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 6. Fit random search on training data\n",
    "random_search.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# 7. Get the best model and hyperparameters\n",
    "best_rf = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters found by RandomizedSearchCV:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# 8. Predict on test data (standard prediction, no custom threshold)\n",
    "y_pred = best_rf.predict(X_test_vectorized)\n",
    "\n",
    "# 9. Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ],
   "id": "71f888cc3a10e016",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best Hyperparameters found by RandomizedSearchCV:\n",
      "{'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': None, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': True}\n",
      "\n",
      "Accuracy: 0.8105395232120451\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         arts       0.77      0.93      0.84        40\n",
      "        crime       0.75      0.90      0.81        49\n",
      "     disaster       0.79      0.71      0.75        42\n",
      "      economy       0.74      0.77      0.75        30\n",
      "    education       0.94      0.90      0.92        81\n",
      "environmental       0.84      0.92      0.88        50\n",
      "       health       0.68      0.84      0.75        55\n",
      "humanInterest       0.78      0.83      0.81        30\n",
      "       labour       0.86      0.80      0.83        60\n",
      "    lifestyle       0.57      0.57      0.57        30\n",
      "        other       0.00      0.00      0.00         1\n",
      "     politics       0.86      0.45      0.59        40\n",
      "     religion       0.92      0.76      0.83        45\n",
      "      science       0.84      0.77      0.80        47\n",
      "       social       0.36      0.71      0.48         7\n",
      "        sport       0.93      0.86      0.89        77\n",
      "       unrest       0.71      0.82      0.76        33\n",
      "      weather       0.91      0.89      0.90        80\n",
      "\n",
      "     accuracy                           0.81       797\n",
      "    macro avg       0.73      0.75      0.73       797\n",
      " weighted avg       0.82      0.81      0.81       797\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karennurlybekov/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/karennurlybekov/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/karennurlybekov/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T16:49:55.017425Z",
     "start_time": "2025-03-04T16:49:54.939631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_class(text, model, tfidf_vectorizer):\n",
    "    \"\"\"\n",
    "    Given a single text string, this function returns the predicted class.\n",
    "    \"\"\"\n",
    "    text_vectorized = tfidf_vectorizer.transform([text])\n",
    "    predicted_label = model.predict(text_vectorized)[0]\n",
    "    return predicted_label\n",
    "\n",
    "df_validation = pd.read_csv(\"data/validation_data.csv\")\n",
    "\n",
    "X_validation_vectorized = vectorizer.transform(df_validation[\"text\"])\n",
    "val_predictions = best_rf.predict(X_validation_vectorized)\n",
    "df_validation[\"predicted_category\"] = val_predictions\n",
    "\n",
    "df_validation.to_csv(\"results/validation_predictions.csv\", index=False)\n",
    "\n",
    "print(\"Validation Predictions:\")\n",
    "print(df_validation)"
   ],
   "id": "dbb89d4d78babb15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Predictions:\n",
      "    category                                               text  \\\n",
      "0       arts  you are using an older browser version. please...   \n",
      "1       arts  on 31 march two of classical music s most acco...   \n",
      "2       arts  bpt after a year of being locked away at home ...   \n",
      "3       arts  pilot uninjured plane hit sandbar while landin...   \n",
      "4       arts  colleen distin photo by facebook toronto sun ....   \n",
      "..       ...                                                ...   \n",
      "103  weather  snow measurements from june 1 varied widely ar...   \n",
      "104  weather  province recognizes world environment day . pr...   \n",
      "105  weather  seattle prnewswire rei co op is investing over...   \n",
      "106  weather  june 1 marked the official start of the atlant...   \n",
      "107  weather  covering up with a hat to ward off heat exhaus...   \n",
      "\n",
      "    predicted_category  \n",
      "0            lifestyle  \n",
      "1                 arts  \n",
      "2                 arts  \n",
      "3             disaster  \n",
      "4                 arts  \n",
      "..                 ...  \n",
      "103            weather  \n",
      "104            weather  \n",
      "105            weather  \n",
      "106            weather  \n",
      "107            weather  \n",
      "\n",
      "[108 rows x 3 columns]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T00:21:20.767412Z",
     "start_time": "2025-03-05T00:21:17.127395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_text(text, model, tfidf_vectorizer):\n",
    "    \"\"\"\n",
    "    Given a single text string, this function returns the predicted class.\n",
    "    :param text: \n",
    "    :param model: \n",
    "    :param tfidf_vectorizer: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    text_vectorized = tfidf_vectorizer.transform([text])\n",
    "    predicted_label = model.predict(text_vectorized)[0]\n",
    "    return predicted_label\n",
    "\n",
    "messege = input(\"Enter a text: \")\n",
    "X_values = vectorizer.transform([messege])\n",
    "single_prediction = predict_text(messege, best_rf, vectorizer)\n",
    "\n",
    "\n",
    "print(\"Validation Predictions:\")\n",
    "print(single_prediction)"
   ],
   "id": "45ebac65b9662a92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Predictions:\n",
      "disaster\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T00:09:20.117386Z",
     "start_time": "2025-03-05T00:09:20.113064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(rf, \"./random_forest.joblib\")"
   ],
   "id": "aad66914c2d613d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./random_forest.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "903d1a4d9777537c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
