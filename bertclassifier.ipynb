{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-01T22:17:54.161383Z",
     "start_time": "2025-03-01T22:17:53.705762Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('use_this_data/llm.csv')\n",
    "\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  category                                               text\n",
       "0     arts  rob delaney vir das galen hopper samson kayo g...\n",
       "1     arts  andris nelsons conducts a joint concert of the...\n",
       "2     arts  warner music group has brought on sherry tan t...\n",
       "3     arts  adele will explore what she s been going throu...\n",
       "4     arts  you are using an older browser version. please..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arts</td>\n",
       "      <td>rob delaney vir das galen hopper samson kayo g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arts</td>\n",
       "      <td>andris nelsons conducts a joint concert of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arts</td>\n",
       "      <td>warner music group has brought on sherry tan t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arts</td>\n",
       "      <td>adele will explore what she s been going throu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arts</td>\n",
       "      <td>you are using an older browser version. please...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:41:19.942207Z",
     "start_time": "2025-03-01T22:41:19.934075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['label_encoded'] = encoder.fit_transform(df['category'])\n",
    "class_names = encoder.classes_\n",
    "\n",
    "\n",
    "df.head()"
   ],
   "id": "3f7a460f05f450d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  category                                               text  label_encoded\n",
       "0     arts  rob delaney vir das galen hopper samson kayo g...              0\n",
       "1     arts  andris nelsons conducts a joint concert of the...              0\n",
       "2     arts  warner music group has brought on sherry tan t...              0\n",
       "3     arts  adele will explore what she s been going throu...              0\n",
       "4     arts  you are using an older browser version. please...              0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arts</td>\n",
       "      <td>rob delaney vir das galen hopper samson kayo g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arts</td>\n",
       "      <td>andris nelsons conducts a joint concert of the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arts</td>\n",
       "      <td>warner music group has brought on sherry tan t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arts</td>\n",
       "      <td>adele will explore what she s been going throu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arts</td>\n",
       "      <td>you are using an older browser version. please...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:42:13.789827Z",
     "start_time": "2025-03-01T22:42:12.659670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "encoded = tokenizer(\n",
    "    df[\"text\"].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"tf\"\n",
    ")\n",
    "\n",
    "input_ids = encoded[\"input_ids\"]\n",
    "attention_mask = encoded[\"attention_mask\"]\n",
    "labels_tf = tf.constant(df[\"label_encoded\"].tolist(), dtype=tf.int32)\n"
   ],
   "id": "c917b4c75d840ee0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T22:44:00.556714Z",
     "start_time": "2025-03-01T22:43:33.683715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=len(class_names)  # number of distinct classes\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "#######################\n",
    "# 5) Train the model on GPU (if available)\n",
    "#######################\n",
    "print(\"GPUs available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "model.fit(\n",
    "    x={\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask\n",
    "    },\n",
    "    y=labels_tf,\n",
    "    epochs=2,\n",
    "    batch_size=2\n",
    ")\n",
    "\n",
    "#######################\n",
    "# 6) Evaluate / get predictions\n",
    "#######################\n",
    "pred_logits = model.predict({\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": attention_mask\n",
    "}).logits\n",
    "\n",
    "pred_label_ids = np.argmax(pred_logits, axis=1)  # integer predictions\n",
    "\n",
    "# True labels\n",
    "y_true = df[\"label_id\"].to_numpy()\n",
    "\n",
    "#######################\n",
    "# 7) Calculate accuracy and per-class metrics\n",
    "#######################\n",
    "overall_accuracy = accuracy_score(y_true, pred_label_ids)\n",
    "print(f\"\\n=== Overall Accuracy: {overall_accuracy:.4f} ===\")\n",
    "\n",
    "report = classification_report(\n",
    "    y_true,\n",
    "    pred_label_ids,\n",
    "    target_names=class_names\n",
    ")\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(report)\n",
    "\n",
    "# (Optional) Confusion Matrix\n",
    "cm = confusion_matrix(y_true, pred_label_ids)\n",
    "print(\"=== Confusion Matrix ===\\n\", cm)\n",
    "\n",
    "# Convert confusion matrix to DataFrame for readability\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "print(\"\\nConfusion Matrix (with labels):\")\n",
    "print(cm_df)"
   ],
   "id": "bc443f5b161f3818",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "635e905e003744c3ab32037aa1f86f52"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs available: []\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 24\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m#######################\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# 5) Train the model on GPU (if available)\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m#######################\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPUs available:\u001B[39m\u001B[38;5;124m\"\u001B[39m, tf\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mlist_physical_devices(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGPU\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m---> 24\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(\n\u001B[1;32m     25\u001B[0m     x\u001B[38;5;241m=\u001B[39m{\n\u001B[1;32m     26\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m: input_ids,\n\u001B[1;32m     27\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m: attention_mask\n\u001B[1;32m     28\u001B[0m     },\n\u001B[1;32m     29\u001B[0m     y\u001B[38;5;241m=\u001B[39mlabels_tf,\n\u001B[1;32m     30\u001B[0m     epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m     31\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m\n\u001B[1;32m     32\u001B[0m )\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m#######################\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m# 6) Evaluate / get predictions\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m#######################\u001B[39;00m\n\u001B[1;32m     37\u001B[0m pred_logits \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict({\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m: input_ids,\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m: attention_mask\n\u001B[1;32m     40\u001B[0m })\u001B[38;5;241m.\u001B[39mlogits\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1229\u001B[0m, in \u001B[0;36mTFPreTrainedModel.fit\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1226\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(keras\u001B[38;5;241m.\u001B[39mModel\u001B[38;5;241m.\u001B[39mfit)\n\u001B[1;32m   1227\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1228\u001B[0m     args, kwargs \u001B[38;5;241m=\u001B[39m convert_batch_encoding(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 1229\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mfit(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tf_keras/src/engine/training.py:1804\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1796\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1797\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1798\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1801\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1802\u001B[0m ):\n\u001B[1;32m   1803\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1804\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_function(iterator)\n\u001B[1;32m   1805\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1806\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:906\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    902\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# Fall through to cond-based initialization.\u001B[39;00m\n\u001B[1;32m    903\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    904\u001B[0m     \u001B[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001B[39;00m\n\u001B[1;32m    905\u001B[0m     \u001B[38;5;66;03m# no_variable_creation function.\u001B[39;00m\n\u001B[0;32m--> 906\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tracing_compilation\u001B[38;5;241m.\u001B[39mcall_function(\n\u001B[1;32m    907\u001B[0m         args, kwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_no_variable_creation_config\n\u001B[1;32m    908\u001B[0m     )\n\u001B[1;32m    909\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    910\u001B[0m   bound_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_variable_creation_fn\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\n\u001B[1;32m    911\u001B[0m       \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds\n\u001B[1;32m    912\u001B[0m   )\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    130\u001B[0m args \u001B[38;5;241m=\u001B[39m args \u001B[38;5;28;01mif\u001B[39;00m args \u001B[38;5;28;01melse\u001B[39;00m ()\n\u001B[1;32m    131\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m kwargs \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[0;32m--> 132\u001B[0m function \u001B[38;5;241m=\u001B[39m trace_function(\n\u001B[1;32m    133\u001B[0m     args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs, tracing_options\u001B[38;5;241m=\u001B[39mtracing_options\n\u001B[1;32m    134\u001B[0m )\n\u001B[1;32m    136\u001B[0m \u001B[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001B[39;00m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001B[0m, in \u001B[0;36mtrace_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    175\u001B[0m     args \u001B[38;5;241m=\u001B[39m tracing_options\u001B[38;5;241m.\u001B[39minput_signature\n\u001B[1;32m    176\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m--> 178\u001B[0m   concrete_function \u001B[38;5;241m=\u001B[39m _maybe_define_function(\n\u001B[1;32m    179\u001B[0m       args, kwargs, tracing_options\n\u001B[1;32m    180\u001B[0m   )\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tracing_options\u001B[38;5;241m.\u001B[39mbind_graph_to_function:\n\u001B[1;32m    183\u001B[0m   concrete_function\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001B[0m, in \u001B[0;36m_maybe_define_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    282\u001B[0m   target_func_type \u001B[38;5;241m=\u001B[39m lookup_func_type\n\u001B[0;32m--> 283\u001B[0m concrete_function \u001B[38;5;241m=\u001B[39m _create_concrete_function(\n\u001B[1;32m    284\u001B[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001B[1;32m    285\u001B[0m )\n\u001B[1;32m    287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tracing_options\u001B[38;5;241m.\u001B[39mfunction_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    288\u001B[0m   tracing_options\u001B[38;5;241m.\u001B[39mfunction_cache\u001B[38;5;241m.\u001B[39madd(\n\u001B[1;32m    289\u001B[0m       concrete_function, current_func_context\n\u001B[1;32m    290\u001B[0m   )\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001B[0m, in \u001B[0;36m_create_concrete_function\u001B[0;34m(function_type, type_context, func_graph, tracing_options)\u001B[0m\n\u001B[1;32m    303\u001B[0m   placeholder_bound_args \u001B[38;5;241m=\u001B[39m function_type\u001B[38;5;241m.\u001B[39mplaceholder_arguments(\n\u001B[1;32m    304\u001B[0m       placeholder_context\n\u001B[1;32m    305\u001B[0m   )\n\u001B[1;32m    307\u001B[0m disable_acd \u001B[38;5;241m=\u001B[39m tracing_options\u001B[38;5;241m.\u001B[39mattributes \u001B[38;5;129;01mand\u001B[39;00m tracing_options\u001B[38;5;241m.\u001B[39mattributes\u001B[38;5;241m.\u001B[39mget(\n\u001B[1;32m    308\u001B[0m     attributes_lib\u001B[38;5;241m.\u001B[39mDISABLE_ACD, \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    309\u001B[0m )\n\u001B[0;32m--> 310\u001B[0m traced_func_graph \u001B[38;5;241m=\u001B[39m func_graph_module\u001B[38;5;241m.\u001B[39mfunc_graph_from_py_func(\n\u001B[1;32m    311\u001B[0m     tracing_options\u001B[38;5;241m.\u001B[39mname,\n\u001B[1;32m    312\u001B[0m     tracing_options\u001B[38;5;241m.\u001B[39mpython_function,\n\u001B[1;32m    313\u001B[0m     placeholder_bound_args\u001B[38;5;241m.\u001B[39margs,\n\u001B[1;32m    314\u001B[0m     placeholder_bound_args\u001B[38;5;241m.\u001B[39mkwargs,\n\u001B[1;32m    315\u001B[0m     \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    316\u001B[0m     func_graph\u001B[38;5;241m=\u001B[39mfunc_graph,\n\u001B[1;32m    317\u001B[0m     add_control_dependencies\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m disable_acd,\n\u001B[1;32m    318\u001B[0m     arg_names\u001B[38;5;241m=\u001B[39mfunction_type_utils\u001B[38;5;241m.\u001B[39mto_arg_names(function_type),\n\u001B[1;32m    319\u001B[0m     create_placeholders\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    320\u001B[0m )\n\u001B[1;32m    322\u001B[0m transform\u001B[38;5;241m.\u001B[39mapply_func_graph_transforms(traced_func_graph)\n\u001B[1;32m    324\u001B[0m graph_capture_container \u001B[38;5;241m=\u001B[39m traced_func_graph\u001B[38;5;241m.\u001B[39mfunction_captures\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/framework/func_graph.py:1059\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001B[0m\n\u001B[1;32m   1056\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[1;32m   1058\u001B[0m _, original_func \u001B[38;5;241m=\u001B[39m tf_decorator\u001B[38;5;241m.\u001B[39munwrap(python_func)\n\u001B[0;32m-> 1059\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m python_func(\u001B[38;5;241m*\u001B[39mfunc_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfunc_kwargs)\n\u001B[1;32m   1061\u001B[0m \u001B[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[39;00m\n\u001B[1;32m   1062\u001B[0m \u001B[38;5;66;03m# TensorArrays and `None`s.\u001B[39;00m\n\u001B[1;32m   1063\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m variable_utils\u001B[38;5;241m.\u001B[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001B[0m, in \u001B[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m default_graph\u001B[38;5;241m.\u001B[39m_variable_creator_scope(scope, priority\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m):  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    596\u001B[0m   \u001B[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[39;00m\n\u001B[1;32m    597\u001B[0m   \u001B[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001B[39;00m\n\u001B[1;32m    598\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(compile_with_xla):\n\u001B[0;32m--> 599\u001B[0m     out \u001B[38;5;241m=\u001B[39m weak_wrapped_fn()\u001B[38;5;241m.\u001B[39m__wrapped__(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    600\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001B[0m, in \u001B[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 41\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m api\u001B[38;5;241m.\u001B[39mconverted_call(\n\u001B[1;32m     42\u001B[0m       original_func,\n\u001B[1;32m     43\u001B[0m       args,\n\u001B[1;32m     44\u001B[0m       kwargs,\n\u001B[1;32m     45\u001B[0m       options\u001B[38;5;241m=\u001B[39mconverter\u001B[38;5;241m.\u001B[39mConversionOptions(\n\u001B[1;32m     46\u001B[0m           recursive\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     47\u001B[0m           optional_features\u001B[38;5;241m=\u001B[39mautograph_options,\n\u001B[1;32m     48\u001B[0m           user_requested\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     49\u001B[0m       ))\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m     51\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:439\u001B[0m, in \u001B[0;36mconverted_call\u001B[0;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    438\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 439\u001B[0m     result \u001B[38;5;241m=\u001B[39m converted_f(\u001B[38;5;241m*\u001B[39meffective_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    440\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    441\u001B[0m     result \u001B[38;5;241m=\u001B[39m converted_f(\u001B[38;5;241m*\u001B[39meffective_args)\n",
      "File \u001B[0;32m/var/folders/8l/g5v37qrs787873ng0tg1_7wh0000gn/T/__autograph_generated_file7c0scq_6.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:331\u001B[0m, in \u001B[0;36mconverted_call\u001B[0;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_in_allowlist_cache(f, options):\n\u001B[1;32m    330\u001B[0m   logging\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllowlisted \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: from cache\u001B[39m\u001B[38;5;124m'\u001B[39m, f)\n\u001B[0;32m--> 331\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ag_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx()\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m ag_ctx\u001B[38;5;241m.\u001B[39mStatus\u001B[38;5;241m.\u001B[39mDISABLED:\n\u001B[1;32m    334\u001B[0m   logging\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllowlisted: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: AutoGraph is disabled in context\u001B[39m\u001B[38;5;124m'\u001B[39m, f)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:460\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[0;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 460\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tf_keras/src/engine/training.py:1381\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.step_function\u001B[0;34m(model, iterator)\u001B[0m\n\u001B[1;32m   1377\u001B[0m     run_step \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mfunction(\n\u001B[1;32m   1378\u001B[0m         run_step, jit_compile\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, reduce_retracing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1379\u001B[0m     )\n\u001B[1;32m   1380\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(iterator)\n\u001B[0;32m-> 1381\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mdistribute_strategy\u001B[38;5;241m.\u001B[39mrun(run_step, args\u001B[38;5;241m=\u001B[39m(data,))\n\u001B[1;32m   1382\u001B[0m outputs \u001B[38;5;241m=\u001B[39m reduce_per_replica(\n\u001B[1;32m   1383\u001B[0m     outputs,\n\u001B[1;32m   1384\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_strategy,\n\u001B[1;32m   1385\u001B[0m     reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_reduction_method,\n\u001B[1;32m   1386\u001B[0m )\n\u001B[1;32m   1387\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:1673\u001B[0m, in \u001B[0;36mStrategyBase.run\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   1668\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscope():\n\u001B[1;32m   1669\u001B[0m   \u001B[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001B[39;00m\n\u001B[1;32m   1670\u001B[0m   \u001B[38;5;66;03m# applied when the caller is also in Eager mode.\u001B[39;00m\n\u001B[1;32m   1671\u001B[0m   fn \u001B[38;5;241m=\u001B[39m autograph\u001B[38;5;241m.\u001B[39mtf_convert(\n\u001B[1;32m   1672\u001B[0m       fn, autograph_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx(), convert_by_default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m-> 1673\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_extended\u001B[38;5;241m.\u001B[39mcall_for_each_replica(fn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:3263\u001B[0m, in \u001B[0;36mStrategyExtendedV1.call_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   3261\u001B[0m   kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   3262\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy()\u001B[38;5;241m.\u001B[39mscope():\n\u001B[0;32m-> 3263\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:4061\u001B[0m, in \u001B[0;36m_DefaultDistributionExtended._call_for_each_replica\u001B[0;34m(self, fn, args, kwargs)\u001B[0m\n\u001B[1;32m   4059\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call_for_each_replica\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn, args, kwargs):\n\u001B[1;32m   4060\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ReplicaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy(), replica_id_in_sync_group\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m-> 4061\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:690\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    689\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[0;32m--> 690\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m converted_call(f, args, kwargs, options\u001B[38;5;241m=\u001B[39moptions)\n\u001B[1;32m    691\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m    692\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:377\u001B[0m, in \u001B[0;36mconverted_call\u001B[0;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[1;32m    374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options)\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39muser_requested \u001B[38;5;129;01mand\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_allowlisted(f):\n\u001B[0;32m--> 377\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options)\n\u001B[1;32m    379\u001B[0m \u001B[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001B[39;00m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001B[39;00m\n\u001B[1;32m    382\u001B[0m \u001B[38;5;66;03m# things like builtins.\u001B[39;00m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39minternal_convert_user_code:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:459\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[0;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[1;32m    456\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mcall(args, kwargs)\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    460\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tf_keras/src/engine/training.py:1370\u001B[0m, in \u001B[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m   1369\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_step\u001B[39m(data):\n\u001B[0;32m-> 1370\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mtrain_step(data)\n\u001B[1;32m   1371\u001B[0m     \u001B[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001B[39;00m\n\u001B[1;32m   1372\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:1709\u001B[0m, in \u001B[0;36mTFPreTrainedModel.train_step\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1706\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompiled_loss(y, y_pred, sample_weight, regularization_losses\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlosses)\n\u001B[1;32m   1708\u001B[0m \u001B[38;5;66;03m# Run backwards pass.\u001B[39;00m\n\u001B[0;32m-> 1709\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mminimize(loss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainable_variables, tape\u001B[38;5;241m=\u001B[39mtape)\n\u001B[1;32m   1711\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompiled_metrics\u001B[38;5;241m.\u001B[39mupdate_state(y, y_pred, sample_weight)\n\u001B[1;32m   1712\u001B[0m \u001B[38;5;66;03m# Collect metrics to return\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tf_keras/src/optimizers/optimizer.py:623\u001B[0m, in \u001B[0;36m_BaseOptimizer.minimize\u001B[0;34m(self, loss, var_list, tape)\u001B[0m\n\u001B[1;32m    602\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001B[39;00m\n\u001B[1;32m    603\u001B[0m \n\u001B[1;32m    604\u001B[0m \u001B[38;5;124;03mThis method simply computes gradient using `tf.GradientTape` and calls\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    620\u001B[0m \u001B[38;5;124;03m  None\u001B[39;00m\n\u001B[1;32m    621\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    622\u001B[0m grads_and_vars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_gradients(loss, var_list, tape)\n\u001B[0;32m--> 623\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_gradients(grads_and_vars)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tf_keras/src/optimizers/optimizer.py:1309\u001B[0m, in \u001B[0;36mOptimizer.apply_gradients\u001B[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001B[0m\n\u001B[1;32m   1307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m skip_gradients_aggregation \u001B[38;5;129;01mand\u001B[39;00m experimental_aggregate_gradients:\n\u001B[1;32m   1308\u001B[0m     grads_and_vars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maggregate_gradients(grads_and_vars)\n\u001B[0;32m-> 1309\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mapply_gradients(grads_and_vars, name\u001B[38;5;241m=\u001B[39mname)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tf_keras/src/optimizers/optimizer.py:731\u001B[0m, in \u001B[0;36m_BaseOptimizer.apply_gradients\u001B[0;34m(self, grads_and_vars, name)\u001B[0m\n\u001B[1;32m    729\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_weight_decay(trainable_variables)\n\u001B[1;32m    730\u001B[0m grads_and_vars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(grads, trainable_variables))\n\u001B[0;32m--> 731\u001B[0m iteration \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_apply_gradients(grads_and_vars)\n\u001B[1;32m    733\u001B[0m \u001B[38;5;66;03m# Apply variable constraints after applying gradients.\u001B[39;00m\n\u001B[1;32m    734\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m variable \u001B[38;5;129;01min\u001B[39;00m trainable_variables:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tf_keras/src/optimizers/optimizer.py:1339\u001B[0m, in \u001B[0;36mOptimizer._internal_apply_gradients\u001B[0;34m(self, grads_and_vars)\u001B[0m\n\u001B[1;32m   1335\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mesh \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_with_dtensor:\n\u001B[1;32m   1336\u001B[0m     \u001B[38;5;66;03m# Skip any usage of strategy logic for DTensor\u001B[39;00m\n\u001B[1;32m   1337\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m_internal_apply_gradients(grads_and_vars)\n\u001B[0;32m-> 1339\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39m__internal__\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39minterim\u001B[38;5;241m.\u001B[39mmaybe_merge_call(\n\u001B[1;32m   1340\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distributed_apply_gradients_fn,\n\u001B[1;32m   1341\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distribution_strategy,\n\u001B[1;32m   1342\u001B[0m     grads_and_vars,\n\u001B[1;32m   1343\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001B[0m, in \u001B[0;36mmaybe_merge_call\u001B[0;34m(fn, strategy, *args, **kwargs)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \n\u001B[1;32m     33\u001B[0m \u001B[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;124;03m  The return value of the `fn` call.\u001B[39;00m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m strategy_supports_no_merge_call():\n\u001B[0;32m---> 51\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(strategy, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m distribute_lib\u001B[38;5;241m.\u001B[39mget_replica_context()\u001B[38;5;241m.\u001B[39mmerge_call(\n\u001B[1;32m     54\u001B[0m       fn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tf_keras/src/optimizers/optimizer.py:1431\u001B[0m, in \u001B[0;36mOptimizer._distributed_apply_gradients_fn\u001B[0;34m(self, distribution, grads_and_vars, **kwargs)\u001B[0m\n\u001B[1;32m   1428\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_step(grad, var)\n\u001B[1;32m   1430\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m grad, var \u001B[38;5;129;01min\u001B[39;00m grads_and_vars:\n\u001B[0;32m-> 1431\u001B[0m     distribution\u001B[38;5;241m.\u001B[39mextended\u001B[38;5;241m.\u001B[39mupdate(\n\u001B[1;32m   1432\u001B[0m         var, apply_grad_to_update_var, args\u001B[38;5;241m=\u001B[39m(grad,), group\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1433\u001B[0m     )\n\u001B[1;32m   1435\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_ema:\n\u001B[1;32m   1436\u001B[0m     _, var_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mgrads_and_vars)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:3007\u001B[0m, in \u001B[0;36mStrategyExtendedV2.update\u001B[0;34m(self, var, fn, args, kwargs, group)\u001B[0m\n\u001B[1;32m   3005\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update(var, fn, args, kwargs, group)\n\u001B[1;32m   3006\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 3007\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_replica_ctx_update(\n\u001B[1;32m   3008\u001B[0m       var, fn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs, group\u001B[38;5;241m=\u001B[39mgroup)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:2886\u001B[0m, in \u001B[0;36mStrategyExtendedV2._replica_ctx_update\u001B[0;34m(self, var, fn, args, kwargs, group)\u001B[0m\n\u001B[1;32m   2883\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmerge_fn\u001B[39m(_, \u001B[38;5;241m*\u001B[39mmerged_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmerged_kwargs):\n\u001B[1;32m   2884\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate(var, fn, merged_args, merged_kwargs, group\u001B[38;5;241m=\u001B[39mgroup)\n\u001B[0;32m-> 2886\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m replica_context\u001B[38;5;241m.\u001B[39mmerge_call(merge_fn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:3478\u001B[0m, in \u001B[0;36mReplicaContextBase.merge_call\u001B[0;34m(self, merge_fn, args, kwargs)\u001B[0m\n\u001B[1;32m   3474\u001B[0m   kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m   3476\u001B[0m merge_fn \u001B[38;5;241m=\u001B[39m autograph\u001B[38;5;241m.\u001B[39mtf_convert(\n\u001B[1;32m   3477\u001B[0m     merge_fn, autograph_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx(), convert_by_default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m-> 3478\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_merge_call(merge_fn, args, kwargs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:3485\u001B[0m, in \u001B[0;36mReplicaContextBase._merge_call\u001B[0;34m(self, merge_fn, args, kwargs)\u001B[0m\n\u001B[1;32m   3482\u001B[0m _push_per_thread_mode(  \u001B[38;5;66;03m# thread-local, so not needed with multiple threads\u001B[39;00m\n\u001B[1;32m   3483\u001B[0m     _CrossReplicaThreadMode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_strategy))  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m   3484\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3485\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m merge_fn(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_strategy, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   3486\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   3487\u001B[0m   _pop_per_thread_mode()\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:690\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    689\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[0;32m--> 690\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m converted_call(f, args, kwargs, options\u001B[38;5;241m=\u001B[39moptions)\n\u001B[1;32m    691\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m    692\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:377\u001B[0m, in \u001B[0;36mconverted_call\u001B[0;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[1;32m    374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options)\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39muser_requested \u001B[38;5;129;01mand\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_allowlisted(f):\n\u001B[0;32m--> 377\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options)\n\u001B[1;32m    379\u001B[0m \u001B[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001B[39;00m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001B[39;00m\n\u001B[1;32m    382\u001B[0m \u001B[38;5;66;03m# things like builtins.\u001B[39;00m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39minternal_convert_user_code:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:459\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[0;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[1;32m    456\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mcall(args, kwargs)\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    460\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:2884\u001B[0m, in \u001B[0;36mStrategyExtendedV2._replica_ctx_update.<locals>.merge_fn\u001B[0;34m(_, *merged_args, **merged_kwargs)\u001B[0m\n\u001B[1;32m   2883\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmerge_fn\u001B[39m(_, \u001B[38;5;241m*\u001B[39mmerged_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmerged_kwargs):\n\u001B[0;32m-> 2884\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate(var, fn, merged_args, merged_kwargs, group\u001B[38;5;241m=\u001B[39mgroup)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:3005\u001B[0m, in \u001B[0;36mStrategyExtendedV2.update\u001B[0;34m(self, var, fn, args, kwargs, group)\u001B[0m\n\u001B[1;32m   3002\u001B[0m   fn \u001B[38;5;241m=\u001B[39m autograph\u001B[38;5;241m.\u001B[39mtf_convert(\n\u001B[1;32m   3003\u001B[0m       fn, autograph_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx(), convert_by_default\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   3004\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_container_strategy()\u001B[38;5;241m.\u001B[39mscope():\n\u001B[0;32m-> 3005\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update(var, fn, args, kwargs, group)\n\u001B[1;32m   3006\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3007\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_replica_ctx_update(\n\u001B[1;32m   3008\u001B[0m       var, fn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs, group\u001B[38;5;241m=\u001B[39mgroup)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:4075\u001B[0m, in \u001B[0;36m_DefaultDistributionExtended._update\u001B[0;34m(self, var, fn, args, kwargs, group)\u001B[0m\n\u001B[1;32m   4072\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update\u001B[39m(\u001B[38;5;28mself\u001B[39m, var, fn, args, kwargs, group):\n\u001B[1;32m   4073\u001B[0m   \u001B[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001B[39;00m\n\u001B[1;32m   4074\u001B[0m   \u001B[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001B[39;00m\n\u001B[0;32m-> 4075\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_non_slot(var, fn, (var,) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mtuple\u001B[39m(args), kwargs, group)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/distribute/distribute_lib.py:4081\u001B[0m, in \u001B[0;36m_DefaultDistributionExtended._update_non_slot\u001B[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001B[0m\n\u001B[1;32m   4077\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update_non_slot\u001B[39m(\u001B[38;5;28mself\u001B[39m, colocate_with, fn, args, kwargs, should_group):\n\u001B[1;32m   4078\u001B[0m   \u001B[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001B[39;00m\n\u001B[1;32m   4079\u001B[0m   \u001B[38;5;66;03m# once that value is used for something.\u001B[39;00m\n\u001B[1;32m   4080\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m UpdateContext(colocate_with):\n\u001B[0;32m-> 4081\u001B[0m     result \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   4082\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m should_group:\n\u001B[1;32m   4083\u001B[0m       \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:690\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    689\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[0;32m--> 690\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m converted_call(f, args, kwargs, options\u001B[38;5;241m=\u001B[39moptions)\n\u001B[1;32m    691\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m    692\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:331\u001B[0m, in \u001B[0;36mconverted_call\u001B[0;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_in_allowlist_cache(f, options):\n\u001B[1;32m    330\u001B[0m   logging\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllowlisted \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: from cache\u001B[39m\u001B[38;5;124m'\u001B[39m, f)\n\u001B[0;32m--> 331\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ag_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx()\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m ag_ctx\u001B[38;5;241m.\u001B[39mStatus\u001B[38;5;241m.\u001B[39mDISABLED:\n\u001B[1;32m    334\u001B[0m   logging\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllowlisted: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: AutoGraph is disabled in context\u001B[39m\u001B[38;5;124m'\u001B[39m, f)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py:459\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[0;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[1;32m    456\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mcall(args, kwargs)\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    460\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tf_keras/src/optimizers/optimizer.py:1428\u001B[0m, in \u001B[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001B[0;34m(var, grad)\u001B[0m\n\u001B[1;32m   1426\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_step_xla(grad, var, \u001B[38;5;28mid\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_var_key(var)))\n\u001B[1;32m   1427\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1428\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_step(grad, var)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tf_keras/src/optimizers/optimizer.py:245\u001B[0m, in \u001B[0;36m_BaseOptimizer._update_step\u001B[0;34m(self, gradient, variable)\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_var_key(variable) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_dict:\n\u001B[1;32m    237\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\n\u001B[1;32m    238\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe optimizer cannot recognize variable \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvariable\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    239\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis usually means you are trying to call the optimizer to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    243\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.keras.optimizers.legacy.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    244\u001B[0m     )\n\u001B[0;32m--> 245\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_step(gradient, variable)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tf_keras/src/optimizers/adam.py:207\u001B[0m, in \u001B[0;36mAdam.update_step\u001B[0;34m(self, gradient, variable)\u001B[0m\n\u001B[1;32m    204\u001B[0m     variable\u001B[38;5;241m.\u001B[39massign_sub((m \u001B[38;5;241m*\u001B[39m alpha) \u001B[38;5;241m/\u001B[39m (tf\u001B[38;5;241m.\u001B[39msqrt(v) \u001B[38;5;241m+\u001B[39m epsilon_hat))\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;66;03m# Dense gradients.\u001B[39;00m\n\u001B[0;32m--> 207\u001B[0m     m\u001B[38;5;241m.\u001B[39massign_add((gradient \u001B[38;5;241m-\u001B[39m m) \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta_1))\n\u001B[1;32m    208\u001B[0m     v\u001B[38;5;241m.\u001B[39massign_add((tf\u001B[38;5;241m.\u001B[39msquare(gradient) \u001B[38;5;241m-\u001B[39m v) \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta_2))\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mamsgrad:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/ops/resource_variable_ops.py:1042\u001B[0m, in \u001B[0;36mBaseResourceVariable.assign_add\u001B[0;34m(self, delta, use_locking, name, read_value)\u001B[0m\n\u001B[1;32m   1026\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Adds a value to this variable.\u001B[39;00m\n\u001B[1;32m   1027\u001B[0m \n\u001B[1;32m   1028\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1039\u001B[0m \u001B[38;5;124;03m  mode it will return `None`.\u001B[39;00m\n\u001B[1;32m   1040\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1041\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _handle_graph(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign_dependencies():\n\u001B[0;32m-> 1042\u001B[0m   assign_add_op \u001B[38;5;241m=\u001B[39m gen_resource_variable_ops\u001B[38;5;241m.\u001B[39massign_add_variable_op(\n\u001B[1;32m   1043\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle,\n\u001B[1;32m   1044\u001B[0m       ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(delta, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype),\n\u001B[1;32m   1045\u001B[0m       name\u001B[38;5;241m=\u001B[39mname)\n\u001B[1;32m   1046\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m read_value:\n\u001B[1;32m   1047\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lazy_read(assign_add_op)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:59\u001B[0m, in \u001B[0;36massign_add_variable_op\u001B[0;34m(resource, value, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# Add nodes to the TensorFlow graph.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;66;03m# Add nodes to the TensorFlow graph.\u001B[39;00m\n\u001B[0;32m---> 59\u001B[0m _, _, _op, _outputs \u001B[38;5;241m=\u001B[39m _op_def_library\u001B[38;5;241m.\u001B[39m_apply_op_helper(\n\u001B[1;32m     60\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAssignAddVariableOp\u001B[39m\u001B[38;5;124m\"\u001B[39m, resource\u001B[38;5;241m=\u001B[39mresource, value\u001B[38;5;241m=\u001B[39mvalue, name\u001B[38;5;241m=\u001B[39mname)\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _op\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/framework/op_def_library.py:776\u001B[0m, in \u001B[0;36m_apply_op_helper\u001B[0;34m(op_type_name, name, **keywords)\u001B[0m\n\u001B[1;32m    771\u001B[0m   _ExtractDefaultTypesAndAllowedTypes(op_def, default_type_attr_map,\n\u001B[1;32m    772\u001B[0m                                       allowed_list_attr_map)\n\u001B[1;32m    774\u001B[0m \u001B[38;5;66;03m# Requires that op_def has passed validation (using the C++\u001B[39;00m\n\u001B[1;32m    775\u001B[0m \u001B[38;5;66;03m# ValidateOpDef() from ../framework/op_def_util.h).\u001B[39;00m\n\u001B[0;32m--> 776\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m g\u001B[38;5;241m.\u001B[39mas_default(), ops\u001B[38;5;241m.\u001B[39mname_scope(name) \u001B[38;5;28;01mas\u001B[39;00m scope:\n\u001B[1;32m    777\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m fallback:\n\u001B[1;32m    778\u001B[0m     _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001B[1;32m    779\u001B[0m                            keywords, default_type_attr_map, attrs, inputs,\n\u001B[1;32m    780\u001B[0m                            input_types)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T09:09:07.391868Z",
     "start_time": "2025-02-24T09:09:06.420173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import keras_nlp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras_hub.src.models.bert import bert_backbone\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import keras_nlp\n",
    "\n",
    "# Load the BERT preprocessing and encoder models from TensorFlow Hub\n",
    "bert_preprocess = keras_nlp.models.BertPreprocessor.from_preset(\"bert_small_en_uncased\",trainable=True)\n",
    "bert_encoder = keras_nlp.models.BertBackbone.from_preset(\"bert_small_en_uncased\", load_weights=True)\n",
    "\n",
    "\n",
    "# Define the input layer\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "\n",
    "# Preprocess the text input\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "\n",
    "# Feed the preprocessed text to the BERT encoder\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "pooled_output = outputs[\"pooled_output\"]\n",
    "\n",
    "# Dropout + multi-class Dense\n",
    "x = tf.keras.layers.Dropout(0.3)(pooled_output)\n",
    "# 18 classes => softmax\n",
    "x = tf.keras.layers.Dense(18, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "\n",
    "\n",
    "# Add a dense layer with sigmoid activation for binary classification\n",
    "# l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "\n",
    "# Define the final model\n",
    "model = tf.keras.Model(inputs=text_input, outputs=x)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# k = 5\n",
    "# kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "# \n",
    "# # Get the index of the \"other\" category in encoded labels\n",
    "# other_class_index = df[df['category'] == \"other\"]['label_encoded'].unique()[0]\n",
    "# \n",
    "# # Store results\n",
    "# fold_accuracies = []\n",
    "# \n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "#     print(f\"\\nFold {fold+1}/{k}\")\n",
    "# \n",
    "#     # Split data\n",
    "#     X_train, X_val = X[train_idx], X[val_idx]\n",
    "#     y_train, y_val = y[train_idx], y[val_idx]\n",
    "# \n",
    "#     # Reinitialize a new model for each fold (important to prevent carry-over effects)\n",
    "#     bert_preprocess = keras_nlp.models.BertPreprocessor.from_preset(\"bert_small_en_uncased\", trainable=True)\n",
    "#     bert_encoder = keras_nlp.models.BertBackbone.from_preset(\"bert_small_en_uncased\", load_weights=True)\n",
    "# \n",
    "#     text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "#     preprocessed_text = bert_preprocess(text_input)\n",
    "#     outputs = bert_encoder(preprocessed_text)\n",
    "#     pooled_output = outputs[\"pooled_output\"]\n",
    "# \n",
    "#     x = tf.keras.layers.Dropout(0.3)(pooled_output)\n",
    "#     x = tf.keras.layers.Dense(18, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "# \n",
    "#     # Define the final model\n",
    "#     model = tf.keras.Model(inputs=text_input, outputs=x)\n",
    "# \n",
    "#     model.compile(\n",
    "#         optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "#         loss='sparse_categorical_crossentropy',\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "# \n",
    "#     # Train model on fold data\n",
    "#     history = model.fit(\n",
    "#         X_train, y_train,\n",
    "#         validation_data=(X_val, y_val),\n",
    "#         epochs=8, \n",
    "#         batch_size=16,\n",
    "#         verbose=1\n",
    "#     )\n",
    "# \n",
    "#     # Evaluate model on validation set\n",
    "#     val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "#     print(f\"Fold {fold+1} Accuracy: {val_accuracy:.4f}\")\n",
    "#     \n",
    "#     # Store accuracy for averaging later\n",
    "#     fold_accuracies.append(val_accuracy)\n",
    "# \n",
    "# \n",
    "# # Compute average accuracy across folds\n",
    "# mean_accuracy = np.mean(fold_accuracies)\n",
    "# std_accuracy = np.std(fold_accuracies)\n",
    "# print(f\"\\nMean Accuracy: {mean_accuracy:.4f}  {std_accuracy:.4f}\")\n",
    "# \n",
    "# \n",
    "# def predict_with_threshold(model, texts, threshold=0.5):\n",
    "#     \"\"\"\n",
    "#     Predicts labels for given texts. If the model's highest confidence score \n",
    "#     is below `threshold`, assigns the \"other\" category.\n",
    "#     \"\"\"\n",
    "#     probs = model.predict(texts)\n",
    "#     max_probs = np.max(probs, axis=1)  # Get highest probability per sample\n",
    "#     predictions = np.argmax(probs, axis=1)  # Get class with highest probability\n",
    "# \n",
    "#     # Assign \"Other\" class if max probability is below threshold\n",
    "#     for i, prob in enumerate(max_probs):\n",
    "#         if prob < threshold:\n",
    "#             predictions[i] = other_class_index  # Use the correct label for \"Other\"\n",
    "# \n",
    "#     return predictions"
   ],
   "id": "37f097c7d27bbad2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_19\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m\n",
       "\n",
       " text (\u001B[38;5;33mInputLayer\u001B[0m)    (\u001B[38;5;45mNone\u001B[0m)                      \u001B[38;5;34m0\u001B[0m  -                 \n",
       "\n",
       " bert_text_classifi  [(\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m),               \u001B[38;5;34m0\u001B[0m  text[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]        \n",
       " (\u001B[38;5;33mBertTextClassifie\u001B[0m  (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m),                                     \n",
       "                      (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)]                                     \n",
       "\n",
       " bert_backbone        [(\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m),      \u001B[38;5;34m28,763,648\u001B[0m  bert_text_classi \n",
       " (\u001B[38;5;33mBertBackbone\u001B[0m)       (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m, \u001B[38;5;34m512\u001B[0m)]              bert_text_classi \n",
       "                                                     bert_text_classi \n",
       "\n",
       " dropout_110          (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)                 \u001B[38;5;34m0\u001B[0m  bert_backbone[\u001B[38;5;34m0\u001B[0m] \n",
       " (\u001B[38;5;33mDropout\u001B[0m)                                                             \n",
       "\n",
       " dense_18 (\u001B[38;5;33mDense\u001B[0m)     (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m18\u001B[0m)              \u001B[38;5;34m9,234\u001B[0m  dropout_110[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] \n",
       "\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
       "\n",
       " text (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       "\n",
       " bert_text_classifi  [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  text[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertTextClassifie</span>  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),                                     \n",
       "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]                                     \n",
       "\n",
       " bert_backbone        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      <span style=\"color: #00af00; text-decoration-color: #00af00\">28,763,648</span>  bert_text_classi \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertBackbone</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]              bert_text_classi \n",
       "                                                     bert_text_classi \n",
       "\n",
       " dropout_110          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  bert_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
       "\n",
       " dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">9,234</span>  dropout_110[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       "\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m28,772,882\u001B[0m (109.76 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,772,882</span> (109.76 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m28,772,882\u001B[0m (109.76 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,772,882</span> (109.76 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T15:29:31.518082Z",
     "start_time": "2025-02-24T13:06:29.368454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# METRICS = [\n",
    "#       tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#       tf.keras.metrics.Precision(name='precision'),\n",
    "#       tf.keras.metrics.Recall(name='recall')\n",
    "# ]\n",
    "# \n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=METRICS)\n",
    "# \n",
    "# model.fit(X_train, y_train, epochs=10)\n",
    "# \n",
    "# model.evaluate(X_test, y_test)\n",
    "\n",
    "\n",
    "# X_train = X_train.astype(str).to_numpy()  # shape = (num_samples,)\n",
    "# y_train = y_train.astype(np.int32).to_numpy()  # shape = (num_samples,)\n",
    "# \n",
    "# X_test = X_test.astype(str).to_numpy()\n",
    "# y_test = y_test.astype(np.int32).to_numpy()\n",
    "# \n",
    "# # Now train\n",
    "# model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='binary_crossentropy',\n",
    "#     metrics=[\n",
    "#         tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#         tf.keras.metrics.Precision(name='precision'),\n",
    "#         tf.keras.metrics.Recall(name='recall')\n",
    "#     ]\n",
    "# )\n",
    "# \n",
    "# model.fit(X_train, y_train, epochs=10)\n",
    "# model.evaluate(X_test, y_test)\n",
    "# \n",
    "# model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     validation_split=0.2,     # or use a separate X_val, y_val\n",
    "#     epochs=10,\n",
    "#     batch_size=32,\n",
    "#     callbacks=[\n",
    "#         tf.keras.callbacks.EarlyStopping(\n",
    "#             monitor=\"val_loss\", \n",
    "#             patience=3, \n",
    "#             restore_best_weights=True\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "# \n",
    "# # 5) Evaluate\n",
    "# model.evaluate(X_test, y_test)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss='sparse_categorical_crossentropy',  # matches integer labels\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ],
   "id": "5d75adbaf4148abd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m106/106\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m1953s\u001B[0m 18s/step - accuracy: 0.8459 - loss: 0.9116 - val_accuracy: 0.5313 - val_loss: 2.0107\n",
      "Epoch 2/10\n",
      "\u001B[1m106/106\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m682s\u001B[0m 6s/step - accuracy: 0.8772 - loss: 0.8060 - val_accuracy: 0.5277 - val_loss: 2.0733\n",
      "Epoch 3/10\n",
      "\u001B[1m106/106\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m774s\u001B[0m 7s/step - accuracy: 0.9008 - loss: 0.7272 - val_accuracy: 0.5277 - val_loss: 2.1262\n",
      "Epoch 4/10\n",
      "\u001B[1m106/106\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m711s\u001B[0m 7s/step - accuracy: 0.9221 - loss: 0.6622 - val_accuracy: 0.5360 - val_loss: 2.1604\n",
      "Epoch 5/10\n",
      "\u001B[1m106/106\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m745s\u001B[0m 7s/step - accuracy: 0.9387 - loss: 0.5862 - val_accuracy: 0.5372 - val_loss: 2.1539\n",
      "Epoch 6/10\n",
      "\u001B[1m106/106\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m727s\u001B[0m 7s/step - accuracy: 0.9744 - loss: 0.5040 - val_accuracy: 0.5407 - val_loss: 2.2595\n",
      "Epoch 7/10\n",
      "\u001B[1m106/106\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m718s\u001B[0m 7s/step - accuracy: 0.9789 - loss: 0.4699 - val_accuracy: 0.5195 - val_loss: 2.2977\n",
      "Epoch 8/10\n",
      "\u001B[1m106/106\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m758s\u001B[0m 7s/step - accuracy: 0.9806 - loss: 0.4463 - val_accuracy: 0.5195 - val_loss: 2.3220\n",
      "Epoch 9/10\n",
      "\u001B[1m106/106\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m699s\u001B[0m 7s/step - accuracy: 0.9892 - loss: 0.4145 - val_accuracy: 0.5325 - val_loss: 2.3402\n",
      "Epoch 10/10\n",
      "\u001B[1m106/106\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m756s\u001B[0m 7s/step - accuracy: 0.9918 - loss: 0.3919 - val_accuracy: 0.5301 - val_loss: 2.4040\n",
      "\u001B[1m34/34\u001B[0m \u001B[32m\u001B[0m\u001B[37m\u001B[0m \u001B[1m59s\u001B[0m 2s/step - accuracy: 0.5363 - loss: 2.4279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4405837059020996, 0.5533522367477417]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ec881e245712eb04"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
