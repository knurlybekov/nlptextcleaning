{
 "cells": [
  {
   "cell_type": "code",
   "id": "f2d34d7e740cfa72",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-20T23:15:26.895046Z",
     "start_time": "2025-02-20T23:15:26.717206Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data_4.csv')\n",
    "\n",
    "df.head()\n",
    "# df[\"clean_text\"] = df[\"fixed_text\"] # only for data_1"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  category                                               text  \\\n",
       "0     arts  you are using an older browser version please ...   \n",
       "1     arts  on march two of classical music s most accompl...   \n",
       "2     arts  bpt after a year of being locked away at home ...   \n",
       "3     arts  pilot uninjured plane hit sandbar while landin...   \n",
       "4     arts  colleen distin photo by facebook toronto sun a...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  older browser version please use version best ...  \n",
       "1  march two classical music accomplished well kn...  \n",
       "2  year locked away home world eager reopen exper...  \n",
       "3  pilot uninjured plane hit landing float plane ...  \n",
       "4  colleen photo sun lost wallet returned owner c...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arts</td>\n",
       "      <td>you are using an older browser version please ...</td>\n",
       "      <td>older browser version please use version best ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arts</td>\n",
       "      <td>on march two of classical music s most accompl...</td>\n",
       "      <td>march two classical music accomplished well kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arts</td>\n",
       "      <td>bpt after a year of being locked away at home ...</td>\n",
       "      <td>year locked away home world eager reopen exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arts</td>\n",
       "      <td>pilot uninjured plane hit sandbar while landin...</td>\n",
       "      <td>pilot uninjured plane hit landing float plane ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arts</td>\n",
       "      <td>colleen distin photo by facebook toronto sun a...</td>\n",
       "      <td>colleen photo sun lost wallet returned owner c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T21:35:18.425162Z",
     "start_time": "2025-02-20T21:33:31.564267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from nltk import pos_tag\n",
    "# from collections import Counter\n",
    "# import nltk\n",
    "# from tqdm import tqdm\n",
    "# tqdm.pandas()\n",
    "# \n",
    "# nltk.download('averaged_perceptron_tagger_eng')\n",
    "# \n",
    "# df[\"text_stopwords_removed\"] = df[\"text_stopwords_removed\"].apply(lambda x: x if isinstance(x, list) else nltk.word_tokenize(x))\n",
    "# \n",
    "# df[\"pos_text\"] = df[\"text_stopwords_removed\"].progress_apply(lambda x: Counter(tag for _, tag in pos_tag(x)))"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/karennurlybekov/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "100%|██████████| 5292/5292 [01:41<00:00, 52.17it/s]\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T22:21:47.450725Z",
     "start_time": "2025-02-20T22:21:47.446382Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "ccfcc9e0976af356",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   category                                               text  \\\n",
       "0     crime  police gather at the publix shopping center at...   \n",
       "1   economy  news feed neighbor posts classifieds calendar ...   \n",
       "2  disaster  bicyclist meets paramedics who saved him after...   \n",
       "3     other  kabul afghanistan ap a helicopter crash overni...   \n",
       "4   weather  london paris moody s esg solutions announced t...   \n",
       "\n",
       "                                          clean_text  label_encoded  \n",
       "0  police gather shopping center scene shooting r...              1  \n",
       "1  news feed neighbor calendar rancho santa marga...              3  \n",
       "2  bicyclist saved crash matt come heart worked b...              2  \n",
       "3  helicopter crash overnight taken least nine af...             10  \n",
       "4  paris moody today provided second party opinio...             17  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crime</td>\n",
       "      <td>police gather at the publix shopping center at...</td>\n",
       "      <td>police gather shopping center scene shooting r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>economy</td>\n",
       "      <td>news feed neighbor posts classifieds calendar ...</td>\n",
       "      <td>news feed neighbor calendar rancho santa marga...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disaster</td>\n",
       "      <td>bicyclist meets paramedics who saved him after...</td>\n",
       "      <td>bicyclist saved crash matt come heart worked b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "      <td>kabul afghanistan ap a helicopter crash overni...</td>\n",
       "      <td>helicopter crash overnight taken least nine af...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weather</td>\n",
       "      <td>london paris moody s esg solutions announced t...</td>\n",
       "      <td>paris moody today provided second party opinio...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T23:17:29.825432Z",
     "start_time": "2025-02-20T23:15:58.658876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def get_pos_counts(doc_text):\n",
    "    \"\"\"\n",
    "    Parse the text with spaCy, count occurrences of chosen PoS types.\n",
    "    Returns a dict of PoS counts.\n",
    "    \"\"\"\n",
    "    doc = nlp(doc_text)\n",
    "    \n",
    "    # Initialize counters\n",
    "    noun_count = 0   # spaCy pos_ == \"NOUN\"\n",
    "    verb_count = 0   # \"VERB\"\n",
    "    adj_count = 0    # \"ADJ\"\n",
    "    adv_count = 0    # \"ADV\"\n",
    "    propn_count = 0  # \"PROPN\" (proper noun)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ == \"NOUN\":\n",
    "            noun_count += 1\n",
    "        elif token.pos_ == \"VERB\":\n",
    "            verb_count += 1\n",
    "        elif token.pos_ == \"ADJ\":\n",
    "            adj_count += 1\n",
    "        elif token.pos_ == \"ADV\":\n",
    "            adv_count += 1\n",
    "        elif token.pos_ == \"PROPN\":\n",
    "            propn_count += 1\n",
    "    \n",
    "    return {\n",
    "        \"noun_count\": noun_count,\n",
    "        \"verb_count\": verb_count,\n",
    "        \"adj_count\": adj_count,\n",
    "        \"adv_count\": adv_count,\n",
    "        \"propn_count\": propn_count\n",
    "    }\n",
    "\n",
    "# Apply the function to \"clean_text\"\n",
    "pos_features_series = df[\"clean_text\"].progress_apply(get_pos_counts)\n",
    "# Convert the series of dictionaries into a DataFrame\n",
    "pos_features_df = pd.DataFrame(pos_features_series.tolist())\n",
    "\n",
    "# Merge PoS features back into the main df if you want\n",
    "df_pos = pd.concat([df, pos_features_df], axis=1)\n",
    "\n",
    "df_pos.head()"
   ],
   "id": "59b41b584af0cab6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5292/5292 [01:30<00:00, 58.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  category                                               text  \\\n",
       "0     arts  you are using an older browser version please ...   \n",
       "1     arts  on march two of classical music s most accompl...   \n",
       "2     arts  bpt after a year of being locked away at home ...   \n",
       "3     arts  pilot uninjured plane hit sandbar while landin...   \n",
       "4     arts  colleen distin photo by facebook toronto sun a...   \n",
       "\n",
       "                                          clean_text  noun_count  verb_count  \\\n",
       "0  older browser version please use version best ...          53          24   \n",
       "1  march two classical music accomplished well kn...         149          51   \n",
       "2  year locked away home world eager reopen exper...          70          44   \n",
       "3  pilot uninjured plane hit landing float plane ...          25           7   \n",
       "4  colleen photo sun lost wallet returned owner c...          55          20   \n",
       "\n",
       "   adj_count  adv_count  propn_count  \n",
       "0         28          5           15  \n",
       "1         81         45           44  \n",
       "2         52         20           40  \n",
       "3          3          0            8  \n",
       "4         12          9           19  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>propn_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arts</td>\n",
       "      <td>you are using an older browser version please ...</td>\n",
       "      <td>older browser version please use version best ...</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arts</td>\n",
       "      <td>on march two of classical music s most accompl...</td>\n",
       "      <td>march two classical music accomplished well kn...</td>\n",
       "      <td>149</td>\n",
       "      <td>51</td>\n",
       "      <td>81</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arts</td>\n",
       "      <td>bpt after a year of being locked away at home ...</td>\n",
       "      <td>year locked away home world eager reopen exper...</td>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arts</td>\n",
       "      <td>pilot uninjured plane hit sandbar while landin...</td>\n",
       "      <td>pilot uninjured plane hit landing float plane ...</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arts</td>\n",
       "      <td>colleen distin photo by facebook toronto sun a...</td>\n",
       "      <td>colleen photo sun lost wallet returned owner c...</td>\n",
       "      <td>55</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T23:17:38.290771Z",
     "start_time": "2025-02-20T23:17:38.285277Z"
    }
   },
   "cell_type": "code",
   "source": "df['category'].value_counts()",
   "id": "fa84d7db64a526b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "science          299\n",
       "disaster         297\n",
       "crime            297\n",
       "weather          296\n",
       "education        296\n",
       "social           295\n",
       "humaninterest    295\n",
       "religion         295\n",
       "health           294\n",
       "politics         294\n",
       "economy          293\n",
       "unrest           293\n",
       "labour           293\n",
       "sport            293\n",
       "arts             291\n",
       "environmental    291\n",
       "lifestyle        291\n",
       "other            289\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T00:01:52.044506Z",
     "start_time": "2025-02-22T00:01:48.022379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_selection import SelectKBest, chi2\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# \n",
    "# \n",
    "# X = df[\"clean_text\"]  # after your cleaning steps\n",
    "# y = df[\"category\"]\n",
    "# \n",
    "# # 2. Train-Test Split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "#                                                     test_size=0.1, \n",
    "#                                                     random_state=42)\n",
    "# \n",
    "# # 3. Vectorize\n",
    "# # tfidf = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', min_df=2)\n",
    "# tfidf = TfidfVectorizer(ngram_range=(1, 2), stop_words='english')\n",
    "# \n",
    "# X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "# X_test_tfidf = tfidf.transform(X_test)\n",
    "# \n",
    "# # 4. Optional: Feature Selection\n",
    "# k = 2000  # or pick another number\n",
    "# selector = SelectKBest(chi2, k=k)\n",
    "# X_train_selected = selector.fit_transform(X_train_tfidf, y_train)\n",
    "# X_test_selected = selector.transform(X_test_tfidf)\n",
    "# \n",
    "# # 5. Model Tuning\n",
    "# param_dist = {\n",
    "#     'n_estimators': [100, 200, 300, 400],\n",
    "#     'max_depth': [10, 20, 30, None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'max_features': ['sqrt', 'log2', 0.5]\n",
    "# }\n",
    "# \n",
    "# rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "# \n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=rf,\n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=20,\n",
    "#     scoring='accuracy',\n",
    "#     cv=5,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# \n",
    "# random_search.fit(X_train_selected, y_train) # or X_train_tfidf for whole X_train_selected for k-best\n",
    "# best_rf = random_search.best_estimator_\n",
    "# \n",
    "# # 6. Evaluate\n",
    "# y_pred = best_rf.predict(X_test_selected)  # or X_test_tfidf for whole or X_test_selected for k-best\n",
    "# acc = accuracy_score(y_test, y_pred)\n",
    "# print(\"Best params:\", random_search.best_params_)\n",
    "# print(\"Test Accuracy:\", acc)"
   ],
   "id": "72a354a11aef6c02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T00:18:21.035410Z",
     "start_time": "2025-02-22T00:16:25.096740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# 1. Load Data\n",
    "# df should have columns: \"clean_text\", \"category\"\n",
    "X = df[\"clean_text\"]\n",
    "y = df[\"category\"]\n",
    "\n",
    "# 2. Train/Test Split (Stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.1, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 3. Define Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words='english'\n",
    "    )),\n",
    "    ('selector', SelectKBest(chi2, k=5000)),  # default k=5000 (will be tuned)\n",
    "    ('clf', RandomForestClassifier(\n",
    "        criterion='gini',\n",
    "        class_weight='balanced',\n",
    "        bootstrap=True,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4. Define Hyperparameter Search Space\n",
    "param_dist = {\n",
    "    'selector__k': [1000, 2000, 3000, 5000],\n",
    "    'clf__n_estimators': [100, 200, 300, 400],\n",
    "    'clf__max_depth': [10, 20, 30, None],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 4],\n",
    "    'clf__max_features': ['sqrt', 'log2', 0.5]\n",
    "}\n",
    "\n",
    "# 5. Cross-validation Setup\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 6. RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,              # number of parameter settings sampled\n",
    "    scoring='accuracy',     # or 'f1_macro', etc.\n",
    "    cv=skf,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 7. Fit the Pipeline\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# 8. Retrieve Best Model and Evaluate\n",
    "best_model = random_search.best_estimator_\n",
    "print(\"Best Params:\", random_search.best_params_)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "rec = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy:      {acc:.4f}\")\n",
    "print(f\"Macro Precision:    {prec:.4f}\")\n",
    "print(f\"Macro Recall:       {rec:.4f}\")\n",
    "print(f\"Macro F1 Score:     {f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "44e25e442d965e52",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karennurlybekov/miniconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'selector__k': 2000, 'clf__n_estimators': 300, 'clf__min_samples_split': 10, 'clf__min_samples_leaf': 1, 'clf__max_features': 'log2', 'clf__max_depth': None}\n",
      "Test Accuracy:      0.5340\n",
      "Macro Precision:    0.5261\n",
      "Macro Recall:       0.5335\n",
      "Macro F1 Score:     0.5085\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         arts       0.50      0.45      0.47        29\n",
      "        crime       0.43      0.67      0.53        30\n",
      "     disaster       0.63      0.40      0.49        30\n",
      "      economy       0.54      0.52      0.53        29\n",
      "    education       0.60      0.87      0.71        30\n",
      "environmental       0.76      0.76      0.76        29\n",
      "       health       0.51      0.86      0.64        29\n",
      "humaninterest       0.45      0.30      0.36        30\n",
      "       labour       0.42      0.45      0.43        29\n",
      "    lifestyle       0.42      0.52      0.46        29\n",
      "        other       0.25      0.03      0.06        29\n",
      "     politics       0.39      0.24      0.30        29\n",
      "     religion       0.83      0.80      0.81        30\n",
      "      science       0.37      0.33      0.35        30\n",
      "       social       0.69      0.30      0.42        30\n",
      "        sport       0.48      0.79      0.60        29\n",
      "       unrest       0.57      0.45      0.50        29\n",
      "      weather       0.63      0.87      0.73        30\n",
      "\n",
      "     accuracy                           0.53       530\n",
      "    macro avg       0.53      0.53      0.51       530\n",
      " weighted avg       0.53      0.53      0.51       530\n",
      "\n"
     ]
    }
   ],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T23:20:22.008985Z",
     "start_time": "2025-02-20T23:20:22.002468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_pos[\"label_encoded\"] = label_encoder.fit_transform(df[\"category\"])\n",
    "\n",
    "df_pos.head()"
   ],
   "id": "b8d16f07cf8c8717",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  category                                               text  \\\n",
       "0     arts  you are using an older browser version please ...   \n",
       "1     arts  on march two of classical music s most accompl...   \n",
       "2     arts  bpt after a year of being locked away at home ...   \n",
       "3     arts  pilot uninjured plane hit sandbar while landin...   \n",
       "4     arts  colleen distin photo by facebook toronto sun a...   \n",
       "\n",
       "                                          clean_text  noun_count  verb_count  \\\n",
       "0  older browser version please use version best ...          53          24   \n",
       "1  march two classical music accomplished well kn...         149          51   \n",
       "2  year locked away home world eager reopen exper...          70          44   \n",
       "3  pilot uninjured plane hit landing float plane ...          25           7   \n",
       "4  colleen photo sun lost wallet returned owner c...          55          20   \n",
       "\n",
       "   adj_count  adv_count  propn_count  label_encoded  \n",
       "0         28          5           15              0  \n",
       "1         81         45           44              0  \n",
       "2         52         20           40              0  \n",
       "3          3          0            8              0  \n",
       "4         12          9           19              0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>propn_count</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arts</td>\n",
       "      <td>you are using an older browser version please ...</td>\n",
       "      <td>older browser version please use version best ...</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arts</td>\n",
       "      <td>on march two of classical music s most accompl...</td>\n",
       "      <td>march two classical music accomplished well kn...</td>\n",
       "      <td>149</td>\n",
       "      <td>51</td>\n",
       "      <td>81</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arts</td>\n",
       "      <td>bpt after a year of being locked away at home ...</td>\n",
       "      <td>year locked away home world eager reopen exper...</td>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arts</td>\n",
       "      <td>pilot uninjured plane hit sandbar while landin...</td>\n",
       "      <td>pilot uninjured plane hit landing float plane ...</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arts</td>\n",
       "      <td>colleen distin photo by facebook toronto sun a...</td>\n",
       "      <td>colleen photo sun lost wallet returned owner c...</td>\n",
       "      <td>55</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T22:15:22.990932Z",
     "start_time": "2025-02-20T22:15:22.985094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import nltk\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# \n",
    "# nltk.download(\"punkt\")\n",
    "# \n",
    "# df[\"tokenized_text\"] = df[\"text\"].apply(lambda x: word_tokenize(x.lower()))\n",
    "# \n",
    "# df.head()\n",
    "# pos_features_df = pd.DataFrame(df[\"pos_text\"].tolist()).fillna(0)\n",
    "# \n",
    "# df = df.drop(columns=[\"pos_text\"])  # Remove the raw PoS column\n",
    "# df = pd.concat([df, pos_features_df], axis=1)  # Merge PoS features\n",
    "\n",
    "df.head()"
   ],
   "id": "7050728fe5f5cff5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   category                                               text  \\\n",
       "0     crime  police gather at the publix shopping center at...   \n",
       "1   economy  news feed neighbor posts classifieds calendar ...   \n",
       "2  disaster  bicyclist meets paramedics who saved him after...   \n",
       "3     other  kabul afghanistan ap a helicopter crash overni...   \n",
       "4   weather  london paris moody s esg solutions announced t...   \n",
       "\n",
       "                                          clean_text  label_encoded  \n",
       "0  police gather shopping center scene shooting r...              1  \n",
       "1  news feed neighbor calendar rancho santa marga...              3  \n",
       "2  bicyclist saved crash matt come heart worked b...              2  \n",
       "3  helicopter crash overnight taken least nine af...             10  \n",
       "4  paris moody today provided second party opinio...             17  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crime</td>\n",
       "      <td>police gather at the publix shopping center at...</td>\n",
       "      <td>police gather shopping center scene shooting r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>economy</td>\n",
       "      <td>news feed neighbor posts classifieds calendar ...</td>\n",
       "      <td>news feed neighbor calendar rancho santa marga...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disaster</td>\n",
       "      <td>bicyclist meets paramedics who saved him after...</td>\n",
       "      <td>bicyclist saved crash matt come heart worked b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "      <td>kabul afghanistan ap a helicopter crash overni...</td>\n",
       "      <td>helicopter crash overnight taken least nine af...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weather</td>\n",
       "      <td>london paris moody s esg solutions announced t...</td>\n",
       "      <td>paris moody today provided second party opinio...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T23:21:30.586664Z",
     "start_time": "2025-02-20T23:20:27.401055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "# tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=1)  \n",
    "# X_tfidf_sparse = tfidf_vectorizer.fit_transform(df[\"clean_text\"])  \n",
    "# # For combining with dense arrays, convert to dense\n",
    "# X_tfidf = X_tfidf_sparse.toarray()  # shape: (n_samples, vocab_size)\n",
    "# \n",
    "# nlp = spacy.load(\"en_core_web_md\")\n",
    "# \n",
    "# def get_word_embeddings_spacy(text):\n",
    "#     doc = nlp(text)\n",
    "#     # doc.vector is the average of token vectors (300D for en_core_web_md)\n",
    "#     return doc.vector\n",
    "# \n",
    "# # Apply to each row\n",
    "# df[\"embeddings\"] = df[\"clean_text\"].apply(get_word_embeddings_spacy)\n",
    "# # Convert list of vectors into a 2D numpy array\n",
    "# X_embeddings = np.vstack(df[\"embeddings\"].values)  # shape: (n_samples, 300)\n",
    "# \n",
    "# # Reduce dimensionality from 300 to 50 (example)\n",
    "# pca = PCA(n_components=50, random_state=42)\n",
    "# X_embeddings_reduced = pca.fit_transform(X_embeddings)  # shape: (n_samples, 50)\n",
    "# \n",
    "# # Optional: Drop \"embeddings\" column\n",
    "# df.drop(columns=[\"embeddings\"], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X_combined = np.hstack((X_tfidf, X_embeddings_reduced))\n",
    "# print(\"X_combined shape:\", X_combined.shape)\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf_sparse = vectorizer.fit_transform(df_pos[\"clean_text\"])  # shape: (n_samples, vocab_size)\n",
    "\n",
    "# If you plan to combine with numeric PoS features, you'll often need a dense array:\n",
    "X_tfidf = X_tfidf_sparse.toarray()  # shape: (n_samples, vocab_size)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) Combine TF-IDF and PoS Features\n",
    "# -----------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "\n",
    "# Extract PoS columns as a NumPy array\n",
    "X_pos = df_pos[[\"noun_count\", \"verb_count\", \"adj_count\", \"adv_count\", \"propn_count\"]].values\n",
    "# shape: (n_samples, 5)\n",
    "\n",
    "# hstack them horizontally\n",
    "X_combined = np.hstack((X_tfidf, X_pos))\n",
    "# shape: (n_samples, vocab_size + 5)\n",
    "\n",
    "# Labels\n",
    "y = df_pos[\"label_encoded\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_combined, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ],
   "id": "ea58827e46ef32b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5004721435316336\n"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T01:51:31.518318Z",
     "start_time": "2025-02-20T01:51:31.504009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import numpy as np\n",
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_md\")  # Medium model with word embeddings\n",
    "# \n",
    "# def get_word_embeddings(text):\n",
    "#     \"\"\"Extracts a 300-dimensional word vector from text using spaCy\"\"\"\n",
    "#     if isinstance(text, list):  # If tokenized, convert back to string\n",
    "#         text = \" \".join(text)\n",
    "#     doc = nlp(text)\n",
    "#     return doc.vector  # 300-dim vector\n",
    "# \n",
    "# # Apply word embeddings to text column\n",
    "# df[\"word_embeddings\"] = df[\"text_processed\"].apply(get_word_embeddings)\n",
    "# \n",
    "# # Convert list of arrays into a NumPy array\n",
    "# X_embeddings = np.vstack(df[\"word_embeddings\"].values)  \n",
    "# \n",
    "# # Drop the temporary embeddings column\n",
    "# df.drop(columns=[\"word_embeddings\"], inplace=True)\n",
    "# \n",
    "# # Convert PoS features to NumPy array\n",
    "# X_pos = pos_features_df.values  \n",
    "# \n",
    "# # Merge Embeddings + PoS Features\n",
    "# X_combined = np.hstack((X_embeddings, X_pos))\n",
    "# \n",
    "# # Define labels\n",
    "# y = df[\"label_encoded\"].values  # Ensure it's numerical (use LabelEncoder if needed)\n",
    "\n",
    "\n",
    "# df.drop(columns=[\"text\", \"tokenized_text\",\"text_stopwords_removed\",\"fixed_text\"], inplace=True)\n",
    "# df.head()"
   ],
   "id": "ed2c4bc51029e37b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  category  label_encoded    RB   VBG   ''    ,  NNP  POS    NN   IN  ...  \\\n",
       "0     arts              0   7.0  11.0   88  183   96  120   5.0  2.0  ...   \n",
       "1     arts              0  28.0  45.0  323  558  239  311  23.0  6.0  ...   \n",
       "2     arts              0   3.0  21.0  182  343  165  216   7.0  8.0  ...   \n",
       "3     arts              0   0.0   6.0   30   75   45   52   3.0  5.0  ...   \n",
       "4     arts              0   1.0   5.0   81  171   91  113   8.0  7.0  ...   \n",
       "\n",
       "    DT   FW   EX  VBN  JJR  VBP   CC   WP   VB  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  2.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  1.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                      text_processed  \n",
       "0  [ 'using ' , 'older ' , 'browser ' , 'version ...  \n",
       "1  [ 'march ' , 'two ' , 'classical ' , 'music ' ...  \n",
       "2  [ 'bpt ' , 'year ' , 'locked ' , 'away ' , 'ho...  \n",
       "3  [ 'pilot ' , 'uninjured ' , 'plane ' , 'hit ' ...  \n",
       "4  [ 'colleen ' , 'distin ' , 'photo ' , 'faceboo...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>label_encoded</th>\n",
       "      <th>RB</th>\n",
       "      <th>VBG</th>\n",
       "      <th>''</th>\n",
       "      <th>,</th>\n",
       "      <th>NNP</th>\n",
       "      <th>POS</th>\n",
       "      <th>NN</th>\n",
       "      <th>IN</th>\n",
       "      <th>...</th>\n",
       "      <th>DT</th>\n",
       "      <th>FW</th>\n",
       "      <th>EX</th>\n",
       "      <th>VBN</th>\n",
       "      <th>JJR</th>\n",
       "      <th>VBP</th>\n",
       "      <th>CC</th>\n",
       "      <th>WP</th>\n",
       "      <th>VB</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arts</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>88</td>\n",
       "      <td>183</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 'using ' , 'older ' , 'browser ' , 'version ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arts</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>323</td>\n",
       "      <td>558</td>\n",
       "      <td>239</td>\n",
       "      <td>311</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 'march ' , 'two ' , 'classical ' , 'music ' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arts</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>182</td>\n",
       "      <td>343</td>\n",
       "      <td>165</td>\n",
       "      <td>216</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 'bpt ' , 'year ' , 'locked ' , 'away ' , 'ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arts</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 'pilot ' , 'uninjured ' , 'plane ' , 'hit ' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arts</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81</td>\n",
       "      <td>171</td>\n",
       "      <td>91</td>\n",
       "      <td>113</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 'colleen ' , 'distin ' , 'photo ' , 'faceboo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T23:21:53.997106Z",
     "start_time": "2025-02-20T23:21:48.523422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=500, max_depth=20, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Decode predicted labels back to text\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test_labels, y_pred_labels)\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Show the first few rows with predictions\n",
    "df_test_results = pd.DataFrame({\"text_processed\": df[\"text_processed\"].iloc[y_test.index], \"actual\": y_test_labels, \"predicted\": y_pred_labels})"
   ],
   "id": "4987b7637f67566e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "         arts       0.55      0.41      0.47        66\n",
      "        crime       0.42      0.48      0.45        61\n",
      "     disaster       0.74      0.40      0.52        70\n",
      "      economy       0.33      0.36      0.34        56\n",
      "    education       0.53      0.79      0.63        61\n",
      "environmental       0.63      0.69      0.66        65\n",
      "       health       0.34      0.75      0.46        51\n",
      "humaninterest       0.55      0.32      0.41        68\n",
      "       labour       0.56      0.67      0.61        55\n",
      "    lifestyle       0.45      0.35      0.39        55\n",
      "        other       0.33      0.05      0.08        44\n",
      "     politics       0.59      0.25      0.35        64\n",
      "     religion       0.47      0.63      0.54        57\n",
      "      science       0.53      0.47      0.50        62\n",
      "       social       0.83      0.15      0.26        65\n",
      "        sport       0.36      0.70      0.48        53\n",
      "       unrest       0.54      0.53      0.53        53\n",
      "      weather       0.53      0.91      0.67        53\n",
      "\n",
      "     accuracy                           0.49      1059\n",
      "    macro avg       0.52      0.49      0.46      1059\n",
      " weighted avg       0.53      0.49      0.47      1059\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'text_processed'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'text_processed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[127], line 30\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification Report:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, report)\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# Show the first few rows with predictions\u001B[39;00m\n\u001B[0;32m---> 30\u001B[0m df_test_results \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext_processed\u001B[39m\u001B[38;5;124m\"\u001B[39m: df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext_processed\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39miloc[y_test\u001B[38;5;241m.\u001B[39mindex], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mactual\u001B[39m\u001B[38;5;124m\"\u001B[39m: y_test_labels, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredicted\u001B[39m\u001B[38;5;124m\"\u001B[39m: y_pred_labels})\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_loc(key)\n\u001B[1;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3810\u001B[0m     ):\n\u001B[1;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'text_processed'"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T00:45:03.444191Z",
     "start_time": "2025-02-20T00:45:03.430960Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "caff446b7e086af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  category                                               text  \\\n",
       "0     arts  you are using an older browser version please ...   \n",
       "1     arts  on march two of classical music s most accompl...   \n",
       "2     arts  bpt after a year of being locked away at home ...   \n",
       "3     arts  pilot uninjured plane hit sandbar while landin...   \n",
       "4     arts  colleen distin photo by facebook toronto sun a...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  ['using', 'older', 'brother', 'version', 'plea...   \n",
       "1  ['march', 'two', 'classical', 'music', 'accomp...   \n",
       "2  ['but', 'year', 'locked', 'away', 'home', 'wor...   \n",
       "3  ['pilot', 'uninjured', 'plane', 'hit', 'sandba...   \n",
       "4  ['college', 'listen', 'photo', 'facebook', 'to...   \n",
       "\n",
       "                              text_stopwords_removed  \\\n",
       "0  [[, 'using, ', ,, 'older, ', ,, 'browser, ', ,...   \n",
       "1  [[, 'march, ', ,, 'two, ', ,, 'classical, ', ,...   \n",
       "2  [[, 'bpt, ', ,, 'year, ', ,, 'locked, ', ,, 'a...   \n",
       "3  [[, 'pilot, ', ,, 'uninjured, ', ,, 'plane, ',...   \n",
       "4  [[, 'colleen, ', ,, 'distin, ', ,, 'photo, ', ...   \n",
       "\n",
       "                                          fixed_text  label_encoded    RB  \\\n",
       "0  using older brother version please use support...              0   7.0   \n",
       "1  march two classical music accomplished well kn...              0  28.0   \n",
       "2  but year locked away home world eager open exp...              0   3.0   \n",
       "3  pilot uninjured plane hit sandbag landing floa...              0   0.0   \n",
       "4  college listen photo facebook toronto sun lost...              0   1.0   \n",
       "\n",
       "    VBG   ''    ,  ...   DT   FW   EX  VBN  JJR  VBP   CC   WP   VB  \\\n",
       "0  11.0   88  183  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  45.0  323  558  ...  2.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  21.0  182  343  ...  1.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3   6.0   30   75  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4   5.0   81  171  ...  0.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                      text_processed  \n",
       "0  [ 'using ' , 'older ' , 'browser ' , 'version ...  \n",
       "1  [ 'march ' , 'two ' , 'classical ' , 'music ' ...  \n",
       "2  [ 'bpt ' , 'year ' , 'locked ' , 'away ' , 'ho...  \n",
       "3  [ 'pilot ' , 'uninjured ' , 'plane ' , 'hit ' ...  \n",
       "4  [ 'colleen ' , 'distin ' , 'photo ' , 'faceboo...  \n",
       "\n",
       "[5 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>text_stopwords_removed</th>\n",
       "      <th>fixed_text</th>\n",
       "      <th>label_encoded</th>\n",
       "      <th>RB</th>\n",
       "      <th>VBG</th>\n",
       "      <th>''</th>\n",
       "      <th>,</th>\n",
       "      <th>...</th>\n",
       "      <th>DT</th>\n",
       "      <th>FW</th>\n",
       "      <th>EX</th>\n",
       "      <th>VBN</th>\n",
       "      <th>JJR</th>\n",
       "      <th>VBP</th>\n",
       "      <th>CC</th>\n",
       "      <th>WP</th>\n",
       "      <th>VB</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arts</td>\n",
       "      <td>you are using an older browser version please ...</td>\n",
       "      <td>['using', 'older', 'brother', 'version', 'plea...</td>\n",
       "      <td>[[, 'using, ', ,, 'older, ', ,, 'browser, ', ,...</td>\n",
       "      <td>using older brother version please use support...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>88</td>\n",
       "      <td>183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 'using ' , 'older ' , 'browser ' , 'version ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arts</td>\n",
       "      <td>on march two of classical music s most accompl...</td>\n",
       "      <td>['march', 'two', 'classical', 'music', 'accomp...</td>\n",
       "      <td>[[, 'march, ', ,, 'two, ', ,, 'classical, ', ,...</td>\n",
       "      <td>march two classical music accomplished well kn...</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>323</td>\n",
       "      <td>558</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 'march ' , 'two ' , 'classical ' , 'music ' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arts</td>\n",
       "      <td>bpt after a year of being locked away at home ...</td>\n",
       "      <td>['but', 'year', 'locked', 'away', 'home', 'wor...</td>\n",
       "      <td>[[, 'bpt, ', ,, 'year, ', ,, 'locked, ', ,, 'a...</td>\n",
       "      <td>but year locked away home world eager open exp...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>182</td>\n",
       "      <td>343</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 'bpt ' , 'year ' , 'locked ' , 'away ' , 'ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arts</td>\n",
       "      <td>pilot uninjured plane hit sandbar while landin...</td>\n",
       "      <td>['pilot', 'uninjured', 'plane', 'hit', 'sandba...</td>\n",
       "      <td>[[, 'pilot, ', ,, 'uninjured, ', ,, 'plane, ',...</td>\n",
       "      <td>pilot uninjured plane hit sandbag landing floa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 'pilot ' , 'uninjured ' , 'plane ' , 'hit ' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arts</td>\n",
       "      <td>colleen distin photo by facebook toronto sun a...</td>\n",
       "      <td>['college', 'listen', 'photo', 'facebook', 'to...</td>\n",
       "      <td>[[, 'colleen, ', ,, 'distin, ', ,, 'photo, ', ...</td>\n",
       "      <td>college listen photo facebook toronto sun lost...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[ 'colleen ' , 'distin ' , 'photo ' , 'faceboo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T00:54:16.790922Z",
     "start_time": "2025-02-20T00:54:16.787987Z"
    }
   },
   "cell_type": "code",
   "source": "print(df[\"label_encoded\"].value_counts(normalize=True))\n",
   "id": "5d9d25ccfb60abf4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_encoded\n",
      "13    0.056500\n",
      "2     0.056122\n",
      "1     0.056122\n",
      "17    0.055933\n",
      "4     0.055933\n",
      "14    0.055745\n",
      "7     0.055745\n",
      "12    0.055745\n",
      "6     0.055556\n",
      "11    0.055556\n",
      "3     0.055367\n",
      "16    0.055367\n",
      "8     0.055367\n",
      "15    0.055367\n",
      "0     0.054989\n",
      "5     0.054989\n",
      "9     0.054989\n",
      "10    0.054611\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f10dfb2624ca2475"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
