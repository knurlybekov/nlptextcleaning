{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-26T00:28:19.430557Z",
     "start_time": "2025-02-26T00:28:18.887347Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data_bert1.csv')\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  category                                               text  \\\n",
       "0     arts  you are using an older browser version. please...   \n",
       "1     arts  on 31 march two of classical music s most acco...   \n",
       "2     arts  bpt after a year of being locked away at home ...   \n",
       "3     arts  pilot uninjured plane hit sandbar while landin...   \n",
       "4     arts  colleen distin photo by facebook toronto sun ....   \n",
       "\n",
       "                                          clean_text  words_removed  \n",
       "0  you are an older browser version . please use ...             50  \n",
       "1  on 31 march two of classical music s most acco...            156  \n",
       "2  after a year of being locked away at home the ...             98  \n",
       "3  pilot uninjured plane hit while landing . a fl...             22  \n",
       "4  colleen photo by sun . a lost wallet been retu...             47  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>words_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arts</td>\n",
       "      <td>you are using an older browser version. please...</td>\n",
       "      <td>you are an older browser version . please use ...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arts</td>\n",
       "      <td>on 31 march two of classical music s most acco...</td>\n",
       "      <td>on 31 march two of classical music s most acco...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arts</td>\n",
       "      <td>bpt after a year of being locked away at home ...</td>\n",
       "      <td>after a year of being locked away at home the ...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arts</td>\n",
       "      <td>pilot uninjured plane hit sandbar while landin...</td>\n",
       "      <td>pilot uninjured plane hit while landing . a fl...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arts</td>\n",
       "      <td>colleen distin photo by facebook toronto sun ....</td>\n",
       "      <td>colleen photo by sun . a lost wallet been retu...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T00:29:40.715792Z",
     "start_time": "2025-02-26T00:28:22.185426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = \"all-mpnet-base-v2\"\n",
    "embedder = SentenceTransformer(model_name)\n",
    "\n",
    "\n",
    "corpus = df[\"clean_text\"].tolist()\n",
    "embeddings = embedder.encode(corpus, show_progress_bar=True)\n"
   ],
   "id": "f91a0bba335b84b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/166 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "baa0cdf27fdd40c1b7e6baa6a2d4e027"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T00:39:24.800867Z",
     "start_time": "2025-02-26T00:29:48.899311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Features (X) and labels (y)\n",
    "X = embeddings\n",
    "y = df[\"category\"].values\n",
    "\n",
    "# Split data into train/test (or train/val/test if you prefer)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"max_features\": ['sqrt', 'log2'],\n",
    "    \"class_weight\": ['balanced_subsample', 'balanced', None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    # Add more params if desired, e.g. \"min_samples_split\": [2, 5]\n",
    "}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    rf_clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=2,               # 3-fold cross validation\n",
    "    scoring=\"accuracy\", # or \"accuracy\", \"f1_weighted\", etc.\n",
    "    n_jobs=-1,          # utilize all CPU cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", grid_search.best_params_)\n",
    "print(\"Best CV score (accuracy):\", grid_search.best_score_)\n",
    "\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\nTEST SET PERFORMANCE:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ],
   "id": "f8ddbbe7833f2c5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 486 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'class_weight': 'balanced_subsample', 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Best CV score (accuracy): 0.4538140027663357\n",
      "\n",
      "TEST SET PERFORMANCE:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         arts       0.33      0.43      0.37        58\n",
      "        crime       0.50      0.75      0.60        59\n",
      "     disaster       0.58      0.49      0.53        59\n",
      "      economy       0.48      0.49      0.48        59\n",
      "    education       0.55      0.73      0.63        59\n",
      "environmental       0.50      0.66      0.57        58\n",
      "       health       0.42      0.66      0.52        59\n",
      "humaninterest       0.40      0.24      0.30        59\n",
      "       labour       0.55      0.47      0.51        59\n",
      "    lifestyle       0.36      0.40      0.38        58\n",
      "        other       0.25      0.02      0.03        58\n",
      "     politics       0.36      0.24      0.29        59\n",
      "     religion       0.48      0.39      0.43        59\n",
      "      science       0.40      0.35      0.37        60\n",
      "       social       0.43      0.22      0.29        59\n",
      "        sport       0.47      0.80      0.59        59\n",
      "       unrest       0.50      0.44      0.47        59\n",
      "      weather       0.70      0.75      0.72        59\n",
      "\n",
      "     accuracy                           0.47      1059\n",
      "    macro avg       0.46      0.47      0.45      1059\n",
      " weighted avg       0.46      0.47      0.45      1059\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f5b30aa219b2c524"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
